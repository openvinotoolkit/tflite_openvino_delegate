From c7693945cefde11f8a2b129f96f4c821b20407c5 Mon Sep 17 00:00:00 2001
From: Anisha Kulkarni
 <anisha.dattatraya.kulkarni@intel.corp-partner.google.com>
Date: Thu, 11 Apr 2024 12:11:03 -0700
Subject: [PATCH] ww15

---
 .bazelversion                                 |    2 -
 WORKSPACE                                     |    4 +
 tensorflow/lite/BUILD                         |   14 +
 tensorflow/lite/delegates/gpu/BUILD           |    8 +-
 .../lite/delegates/openvino/.clang-format     |  151 +++
 tensorflow/lite/delegates/openvino/BUILD      |  281 +++++
 .../openvino/e2e_openvino_fp32_anisha.cpp     |  166 +++
 .../delegates/openvino/openvino_delegate.cc   |  233 ++++
 .../delegates/openvino/openvino_delegate.h    |   91 ++
 .../openvino/openvino_delegate_adapter.cc     |   64 +
 .../openvino_delegate_builder_test.cc         |  101 ++
 .../openvino/openvino_delegate_core.cc        |   80 ++
 .../openvino/openvino_delegate_core.h         |   51 +
 .../openvino/openvino_delegate_core_test.cc   |  135 ++
 .../openvino/openvino_delegate_external.cc    |   53 +
 .../openvino_delegate_external_test.cc        |  101 ++
 .../openvino/openvino_delegate_kernel.cc      |   80 ++
 .../openvino/openvino_delegate_kernel.h       |   53 +
 .../openvino/openvino_delegate_test.cc        |  206 +++
 .../openvino/openvino_graph_builder.cc        |  146 +++
 .../openvino/openvino_graph_builder.h         |  215 ++++
 .../openvino/openvino_graph_builder_test.cc   | 1114 +++++++++++++++++
 .../lite/delegates/openvino/operations/BUILD  |   74 ++
 .../openvino/operations/include/add.h         |   17 +
 .../operations/include/average_pool_2d.h      |   17 +
 .../openvino/operations/include/concat.h      |   17 +
 .../openvino/operations/include/conv2d.h      |   17 +
 .../operations/include/depthwise_conv2d.h     |   17 +
 .../openvino/operations/include/dequantize.h  |   17 +
 .../openvino/operations/include/hardswish.h   |   17 +
 .../openvino/operations/include/logistic.h    |   17 +
 .../openvino/operations/include/maxpool2d.h   |   17 +
 .../openvino/operations/include/mean.h        |   17 +
 .../openvino/operations/include/mul.h         |   17 +
 .../openvino/operations/include/relu.h        |   17 +
 .../openvino/operations/include/relu6.h       |   17 +
 .../openvino/operations/include/reshape.h     |   17 +
 .../operations/include/resize_bilinear.h      |   17 +
 .../openvino/operations/include/softmax.h     |   17 +
 .../openvino/operations/include/tanh.h        |   17 +
 .../operations/include/transpose_conv.h       |   21 +
 .../operations/openvino_node_manager.h        |   31 +
 .../openvino/operations/operations_base.h     |  192 +++
 .../delegates/openvino/operations/src/add.cc  |   26 +
 .../operations/src/average_pool_2d.cc         |   40 +
 .../openvino/operations/src/concat.cc         |   36 +
 .../openvino/operations/src/conv2d.cc         |   56 +
 .../operations/src/depthwise_conv2d.cc        |   70 ++
 .../openvino/operations/src/dequantize.cc     |   19 +
 .../openvino/operations/src/hardswish.cc      |   16 +
 .../openvino/operations/src/logistic.cc       |   17 +
 .../openvino/operations/src/maxpool2d.cc      |   38 +
 .../delegates/openvino/operations/src/mean.cc |   54 +
 .../delegates/openvino/operations/src/mul.cc  |   26 +
 .../delegates/openvino/operations/src/relu.cc |   16 +
 .../openvino/operations/src/relu6.cc          |   16 +
 .../openvino/operations/src/reshape.cc        |   30 +
 .../operations/src/resize_bilinear.cc         |   40 +
 .../openvino/operations/src/softmax.cc        |   22 +
 .../delegates/openvino/operations/src/tanh.cc |   18 +
 .../openvino/operations/src/transpose_conv.cc |   95 ++
 .../delegates/openvino/operations_base.cc     |    0
 .../openvino/stable_delegate_settings.json    |    6 +
 tensorflow/lite/tflite_with_openvino.cc       |   14 +
 tensorflow/lite/tools/delegates/BUILD         |   36 +-
 .../delegates/openvino_delegate_provider.cc   |   63 +
 tensorflow/lite/tools/evaluation/BUILD        |   14 +-
 tensorflow/lite/tools/evaluation/stages/BUILD |    4 +-
 tensorflow/lite/tools/evaluation/tasks/BUILD  |    4 +-
 .../evaluation/tasks/inference_diff/BUILD     |    4 +-
 tensorflow/lite/tools/evaluation/utils.cc     |   13 +
 third_party/openvino/openvino.bzl             |   20 +
 tools/build_tfmodel.py                        |  152 +++
 73 files changed, 4891 insertions(+), 30 deletions(-)
 delete mode 100644 .bazelversion
 create mode 100644 tensorflow/lite/delegates/openvino/.clang-format
 create mode 100644 tensorflow/lite/delegates/openvino/BUILD
 create mode 100644 tensorflow/lite/delegates/openvino/e2e_openvino_fp32_anisha.cpp
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate.h
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_adapter.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_builder_test.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_core.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_core.h
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_core_test.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_external.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_external_test.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_kernel.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_kernel.h
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_delegate_test.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_graph_builder.cc
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_graph_builder.h
 create mode 100644 tensorflow/lite/delegates/openvino/openvino_graph_builder_test.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/BUILD
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/add.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/average_pool_2d.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/concat.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/conv2d.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/depthwise_conv2d.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/dequantize.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/hardswish.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/logistic.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/maxpool2d.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/mean.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/mul.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/relu.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/relu6.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/reshape.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/resize_bilinear.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/softmax.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/tanh.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/include/transpose_conv.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/openvino_node_manager.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/operations_base.h
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/add.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/average_pool_2d.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/concat.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/conv2d.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/depthwise_conv2d.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/dequantize.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/hardswish.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/logistic.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/maxpool2d.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/mean.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/mul.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/relu.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/relu6.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/reshape.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/resize_bilinear.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/softmax.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/tanh.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations/src/transpose_conv.cc
 create mode 100644 tensorflow/lite/delegates/openvino/operations_base.cc
 create mode 100644 tensorflow/lite/delegates/openvino/stable_delegate_settings.json
 create mode 100644 tensorflow/lite/tflite_with_openvino.cc
 create mode 100644 tensorflow/lite/tools/delegates/openvino_delegate_provider.cc
 create mode 100644 third_party/openvino/openvino.bzl
 create mode 100644 tools/build_tfmodel.py

diff --git a/.bazelversion b/.bazelversion
deleted file mode 100644
index b536fbc50613..000000000000
--- a/.bazelversion
+++ /dev/null
@@ -1,2 +0,0 @@
-6.1.0
-# NOTE: Update Bazel version in tensorflow/tools/ci_build/release/common.sh.oss
\ No newline at end of file
diff --git a/WORKSPACE b/WORKSPACE
index 6a85ffeb29a2..b57f13c0c842 100644
--- a/WORKSPACE
+++ b/WORKSPACE
@@ -90,3 +90,7 @@ tf_workspace1()
 load("@//tensorflow:workspace0.bzl", "tf_workspace0")
 
 tf_workspace0()
+
+load("//third_party:openvino/openvino.bzl", "openvino_configure")
+
+openvino_configure(name = "intel_openvino")
diff --git a/tensorflow/lite/BUILD b/tensorflow/lite/BUILD
index bb2de515da95..000cf0d382fe 100644
--- a/tensorflow/lite/BUILD
+++ b/tensorflow/lite/BUILD
@@ -1314,6 +1314,20 @@ cc_library(
     compatible_with = get_compatible_with_portable(),
     deps = ["//tensorflow/lite/core/api:error_reporter"],
 )
+# Link this library to inject OpenVINO delegate to TFLite runtime automatically
+# by utilizing the weak symbols if they're supported by the platform.
+cc_library(
+    name = "tflite_with_openvino",
+    srcs = ["tflite_with_openvino.cc"],
+    copts = tflite_copts() + tflite_copts_warnings(),
+    linkstatic = True,
+    deps = [
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/delegates/openvino:openvino_delegate",
+    ],
+    alwayslink = 1,
+)
+
 
 # Shared lib target for convenience, pulls in the core runtime and builtin ops.
 # Note: This target is not yet finalized, and the exact set of exported (C/C++)
diff --git a/tensorflow/lite/delegates/gpu/BUILD b/tensorflow/lite/delegates/gpu/BUILD
index 6e767beb635c..e9c86bd1de92 100644
--- a/tensorflow/lite/delegates/gpu/BUILD
+++ b/tensorflow/lite/delegates/gpu/BUILD
@@ -1,8 +1,8 @@
 load("@bazel_skylib//lib:selects.bzl", "selects")
 load("//tensorflow/lite:special_rules.bzl", "tflite_extra_gles_deps", "tflite_portable_test_suite")
 load("//tensorflow/lite/delegates/gpu:build_defs.bzl", "gpu_delegate_linkopts")
-load("@build_bazel_rules_apple//apple:ios.bzl", "ios_static_framework")
-load("@build_bazel_rules_apple//apple:macos.bzl", "macos_dylib")
+#load("@build_bazel_rules_apple//apple:ios.bzl", "ios_static_framework")
+#load("@build_bazel_rules_apple//apple:macos.bzl", "macos_dylib")
 load(
     "//tensorflow/core/platform:build_config_root.bzl",
     "tf_gpu_tests_tags",
@@ -166,7 +166,7 @@ cc_binary(
 )
 
 # bazel build -c opt --cpu ios_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt -fvisibility=hidden --linkopt -s --strip always --cxxopt=-std=c++14 :libtensorflowlite_gpu_metal --apple_platform_type=ios
-ios_static_framework(
+'''ios_static_framework(
     name = "tensorflow_lite_gpu_framework",
     hdrs = [
         "metal_delegate.h",
@@ -194,7 +194,7 @@ macos_dylib(
         ":metal_delegate",
         ":metal_delegate_internal",
     ],
-)
+)'''
 
 cc_library(
     name = "api",
diff --git a/tensorflow/lite/delegates/openvino/.clang-format b/tensorflow/lite/delegates/openvino/.clang-format
new file mode 100644
index 000000000000..98a66ee00245
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/.clang-format
@@ -0,0 +1,151 @@
+---
+Language:        Cpp
+# BasedOnStyle:  Google
+AccessModifierOffset: -4
+AlignAfterOpenBracket: Align
+AlignConsecutiveAssignments: false
+AlignConsecutiveDeclarations: false
+AlignEscapedNewlines: Left
+AlignOperands:   true
+AlignTrailingComments: true
+AllowAllParametersOfDeclarationOnNextLine: true
+AllowShortBlocksOnASingleLine: false
+AllowShortCaseLabelsOnASingleLine: false
+AllowShortFunctionsOnASingleLine: All
+AllowShortIfStatementsOnASingleLine: true
+AllowShortLoopsOnASingleLine: true
+AlwaysBreakAfterDefinitionReturnType: None
+AlwaysBreakAfterReturnType: None
+AlwaysBreakBeforeMultilineStrings: true
+AlwaysBreakTemplateDeclarations: Yes
+BinPackArguments: true
+BinPackParameters: true
+BraceWrapping:   
+  AfterClass:      false
+  AfterControlStatement: false
+  AfterEnum:       false
+  AfterFunction:   false
+  AfterNamespace:  false
+  AfterObjCDeclaration: false
+  AfterStruct:     false
+  AfterUnion:      false
+  AfterExternBlock: false
+  BeforeCatch:     false
+  BeforeElse:      false
+  IndentBraces:    false
+  SplitEmptyFunction: true
+  SplitEmptyRecord: true
+  SplitEmptyNamespace: true
+BreakBeforeBinaryOperators: None
+BreakBeforeBraces: Attach
+BreakBeforeInheritanceComma: false
+BreakInheritanceList: BeforeColon
+BreakBeforeTernaryOperators: true
+BreakConstructorInitializersBeforeComma: false
+BreakConstructorInitializers: BeforeColon
+BreakAfterJavaFieldAnnotations: false
+BreakStringLiterals: true
+ColumnLimit:     100
+CommentPragmas:  '^ IWYU pragma:'
+CompactNamespaces: false
+ConstructorInitializerAllOnOneLineOrOnePerLine: true
+ConstructorInitializerIndentWidth: 4
+ContinuationIndentWidth: 4
+Cpp11BracedListStyle: true
+DerivePointerAlignment: true
+DisableFormat:   false
+ExperimentalAutoDetectBinPacking: false
+FixNamespaceComments: true
+ForEachMacros:   
+  - foreach
+  - Q_FOREACH
+  - BOOST_FOREACH
+IncludeBlocks:   Preserve
+IncludeCategories: 
+  - Regex:           '^<ext/.*\.h>'
+    Priority:        2
+  - Regex:           '^<.*\.h>'
+    Priority:        1
+  - Regex:           '^<.*'
+    Priority:        2
+  - Regex:           '.*'
+    Priority:        3
+IncludeIsMainRegex: '([-_](test|unittest))?$'
+IndentCaseLabels: true
+IndentPPDirectives: None
+IndentWidth:     4
+IndentWrappedFunctionNames: false
+JavaScriptQuotes: Leave
+JavaScriptWrapImports: true
+KeepEmptyLinesAtTheStartOfBlocks: false
+MacroBlockBegin: ''
+MacroBlockEnd:   ''
+MaxEmptyLinesToKeep: 1
+NamespaceIndentation: None
+ObjCBinPackProtocolList: Never
+ObjCBlockIndentWidth: 4
+ObjCSpaceAfterProperty: false
+ObjCSpaceBeforeProtocolList: true
+PenaltyBreakAssignment: 2
+PenaltyBreakBeforeFirstCallParameter: 1
+PenaltyBreakComment: 300
+PenaltyBreakFirstLessLess: 120
+PenaltyBreakString: 1000
+PenaltyBreakTemplateDeclaration: 10
+PenaltyExcessCharacter: 1000000
+PenaltyReturnTypeOnItsOwnLine: 200
+PointerAlignment: Left
+RawStringFormats: 
+  - Language:        Cpp
+    Delimiters:      
+      - cc
+      - CC
+      - cpp
+      - Cpp
+      - CPP
+      - 'c++'
+      - 'C++'
+    CanonicalDelimiter: ''
+    BasedOnStyle:    google
+  - Language:        TextProto
+    Delimiters:      
+      - pb
+      - PB
+      - proto
+      - PROTO
+    EnclosingFunctions: 
+      - EqualsProto
+      - EquivToProto
+      - PARSE_PARTIAL_TEXT_PROTO
+      - PARSE_TEST_PROTO
+      - PARSE_TEXT_PROTO
+      - ParseTextOrDie
+      - ParseTextProtoOrDie
+    CanonicalDelimiter: ''
+    BasedOnStyle:    google
+ReflowComments:  true
+SortIncludes:    true
+SortUsingDeclarations: true
+SpaceAfterCStyleCast: false
+SpaceAfterTemplateKeyword: true
+SpaceBeforeAssignmentOperators: true
+SpaceBeforeCpp11BracedList: false
+SpaceBeforeCtorInitializerColon: true
+SpaceBeforeInheritanceColon: true
+SpaceBeforeParens: ControlStatements
+SpaceBeforeRangeBasedForLoopColon: true
+SpaceInEmptyParentheses: false
+SpacesBeforeTrailingComments: 2
+SpacesInAngles:  false
+SpacesInContainerLiterals: true
+SpacesInCStyleCastParentheses: false
+SpacesInParentheses: false
+SpacesInSquareBrackets: false
+Standard:        Auto
+StatementMacros: 
+  - Q_UNUSED
+  - QT_REQUIRE_VERSION
+TabWidth:        8
+UseTab:          Never
+...
+
diff --git a/tensorflow/lite/delegates/openvino/BUILD b/tensorflow/lite/delegates/openvino/BUILD
new file mode 100644
index 000000000000..7401dfc81fc6
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/BUILD
@@ -0,0 +1,281 @@
+load("//tensorflow/lite:build_def.bzl", "tflite_copts", "tflite_linkopts_no_undefined","tflite_cc_shared_object")
+load("//tensorflow/lite:special_rules.bzl", "internal_visibility_allowlist", "tflite_portable_test_suite_combined")
+load("//tensorflow:tensorflow.bzl", "get_compatible_with_portable")
+
+package(
+    default_visibility = ["//visibility:public"],
+    licenses = ["notice"],
+)
+
+exports_files([
+    "openvino_delegate.h",
+])
+
+cc_library(
+    name ="openvino_graph_builder",
+    srcs = ["openvino_graph_builder.cc"],
+    hdrs = ["openvino_graph_builder.h"],
+    tags = [
+        "manual",
+        "nobuilder",
+    ],
+    deps = [
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/c:c_api_types",
+        "//tensorflow/lite/c:c_api",
+        "//tensorflow/lite/c:c_api_experimental",
+        "//tensorflow/lite/delegates/openvino/operations:operations_base",
+        "//tensorflow/lite:kernel_api",
+        "//tensorflow/lite/kernels:kernel_util",
+        "//tensorflow/lite/tools:logging",
+        "//tensorflow/lite/kernels:builtin_ops",
+        "@intel_openvino//:openvino",
+    ],
+)
+
+cc_library(
+    name ="openvino_delegate_core",
+    srcs = ["openvino_delegate_core.cc"],
+    hdrs = ["openvino_delegate_core.h"],
+    tags = [
+        "manual",
+        "nobuilder",
+    ],
+    deps = [
+        ":openvino_graph_builder",
+        "//tensorflow/lite:kernel_api",
+        "//tensorflow/lite/tools:logging",
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/c:c_api",
+        "//tensorflow/lite/c:c_api_types",
+        "//tensorflow/lite/c:c_api_experimental",
+        "//tensorflow/lite/kernels:kernel_util",
+        "@intel_openvino//:openvino",
+    ],
+)
+
+cc_library(
+    name ="openvino_delegate_kernel",
+    srcs = ["openvino_delegate_kernel.cc"],
+    hdrs = ["openvino_delegate_kernel.h"],
+    tags = [
+        "manual",
+        "nobuilder",
+    ],
+    deps = [
+        ":openvino_delegate_core",
+        "//tensorflow/lite:kernel_api",
+        "//tensorflow/lite/tools:logging",
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/c:c_api",
+        "//tensorflow/lite/c:c_api_types",
+        "//tensorflow/lite/c:c_api_experimental",
+        "//tensorflow/lite/delegates/utils:simple_opaque_delegate",
+        "//tensorflow/lite/delegates/utils:simple_delegate",
+        "//tensorflow/lite/kernels:kernel_util",
+        "@intel_openvino//:openvino",
+    ],
+)
+
+cc_library(
+    name = "openvino_delegate",
+    srcs = ["openvino_delegate.cc"],
+    hdrs = ["openvino_delegate.h"],
+    tags = [
+        "manual",
+        "nobuilder",
+    ],
+    deps = [
+        ":openvino_delegate_kernel",
+        "//tensorflow/lite:kernel_api",
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/c:c_api",
+        "//tensorflow/lite/c:c_api_types",
+        "//tensorflow/lite/kernels:padding",
+        "//tensorflow/lite/kernels/internal:compatibility",
+        "//tensorflow/lite/kernels/internal:tensor",
+        "//tensorflow/lite/c:c_api_experimental",
+        "//tensorflow/lite/delegates/utils:simple_opaque_delegate",
+        "//tensorflow/lite/kernels:builtin_ops",
+        "@intel_openvino//:openvino",
+    ],
+)
+cc_test(
+    name = "openvino_graph_builder_test",
+    srcs = ["openvino_graph_builder_test.cc"],
+    linkopts = select({
+        "//conditions:default": [],
+    }),
+    deps = [
+        ":openvino_graph_builder",
+        "@com_google_googletest//:gtest_main",
+    ],
+)
+
+'''cc_library(
+    name ="openvino_delegate_kernel",
+    srcs = ["openvino_delegate_kernel.cc"],
+    hdrs = ["openvino_delegate_kernel.h"],
+    tags = [
+        "manual",
+        "nobuilder",
+    ],
+    linkstatic = True,
+    deps = [
+        "//tensorflow/lite:kernel_api",
+        "//tensorflow/lite/tools:logging",
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/core/api",
+        "//tensorflow/lite/delegates/utils:simple_opaque_delegate",
+        "//tensorflow/lite/kernels:kernel_util",
+        "@intel_openvino//:openvino",
+    ],
+)
+'''
+
+cc_library(
+    name = "openvino_external_delegate",
+    srcs = [
+        "openvino_delegate_external.cc",
+    ],
+    copts = tflite_copts() + ["-fexceptions"],
+    deps = [
+        "//tensorflow/lite/c:c_api",
+        "//tensorflow/lite/c:c_api_experimental",
+        "//tensorflow/lite/c:c_api_types",
+        ":openvino_delegate",
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/tools:command_line_flags",
+        "//tensorflow/lite/tools:logging",
+        "//tensorflow/lite/delegates/utils:simple_opaque_delegate",
+        "//tensorflow/lite/delegates/utils/experimental/stable_delegate:stable_delegate_interface",
+        "//tensorflow/lite/acceleration/configuration/c:delegate_plugin",
+        "//tensorflow/lite/acceleration/configuration/c:stable_delegate",
+        "//tensorflow/lite/delegates/external:external_delegate_interface",
+        "//tensorflow/lite/delegates/utils/experimental/stable_delegate:delegate_loader",
+    ],
+)
+
+tflite_cc_shared_object(
+    name = "tensorflowlite_openvino_stable_delegate",
+    testonly = True,
+    linkopts = tflite_linkopts_no_undefined() + select({
+        "//tensorflow:windows": [],
+        "//conditions:default": [
+            # Expose necessary symbols only.
+            "-Wl,--version-script,$(location //tensorflow/lite/delegates/utils/experimental/stable_delegate:version_script.lds)",
+        ],
+    }),
+    per_os_targets = True,
+    deps = [
+        ":openvino_external_delegate",
+        "//tensorflow/lite/delegates/utils/experimental/stable_delegate:version_script.lds",
+    ],
+)
+
+cc_test(
+    name = "openvino_delegate_external_test",
+    srcs = ["openvino_delegate_external_test.cc"],
+    linkopts = select({
+        "//conditions:default": [],
+    }),
+    deps = [
+        ":openvino_external_delegate",
+        "@com_google_googletest//:gtest_main",
+    ],
+)
+
+cc_test(
+    name = "openvino_delegate_core_test",
+    srcs = ["openvino_delegate_core_test.cc"],
+    linkopts = select({
+        "//conditions:default": [],
+    }),
+    deps = [
+        ":openvino_delegate_core",
+        "@com_google_googletest//:gtest_main",
+    ],
+)
+
+cc_library(
+    name = "openvino_delegate_provider",
+    srcs = ["//tensorflow/lite/tools/delegates/openvino_delegate_provider.cc"],
+    copts = tflite_copts(),
+    deps = [
+        ":openvino_delegate",
+        "//tensorflow/lite/tools/delegates:delegate_provider_hdr",
+     ],
+    alwayslink = 1,
+)
+
+cc_library(
+    name = "openvino_delegate_hdrs_only",
+    hdrs = ["openvino_delegate.h"],
+    compatible_with = get_compatible_with_portable(),
+    visibility = internal_visibility_allowlist(),
+    deps = [
+        "//tensorflow/lite/c:common",
+    ],
+)
+
+cc_library(
+    name = "openvino_delegate_test_mode",
+    srcs = ["openvino_delegate.cc"],
+    hdrs = ["openvino_delegate.h"],
+    copts = tflite_copts() + ["-fexceptions"] + ["-DOPENVINO_DELEGATE_TEST_MODE=1"],
+    linkstatic = True,
+    deps = [
+        ":openvino_delegate_kernel",
+        "//tensorflow/lite:kernel_api",
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/kernels:padding",
+        "//tensorflow/lite/kernels/internal:compatibility",
+        "//tensorflow/lite/kernels/internal:tensor",
+        "//tensorflow/lite/kernels/internal/utils:sparsity_format_converter",
+        "@intel_openvino//:openvino",
+    ],
+)
+cc_binary(
+	name = "e2e_npu_gemini",
+	srcs = ["e2e_openvino_fp32_anisha.cpp"],
+	linkopts = select({
+	"//conditions:default": [],
+        }),
+	deps = [
+	    "@intel_openvino//:openvino",
+	],
+)
+cc_test(
+    name = "openvino_delegate_builder_test",
+    srcs = ["openvino_delegate_builder_test.cc"],
+    linkopts = select({
+        "//conditions:default": [],
+    }),
+    deps = [
+        ":openvino_delegate_test_mode",
+        "@com_google_googletest//:gtest_main",
+    ],
+)
+
+cc_test(
+    name = "openvino_delegate_test",
+    srcs = ["openvino_delegate_test.cc"],
+    linkopts = select({
+        "//conditions:default": [],
+    }),
+    deps = [
+        ":openvino_delegate",
+        "@com_google_googletest//:gtest_main",
+    ],
+)
+
+filegroup(
+    name = "openvino_delegate_tests",
+    testonly = True,
+    srcs = [
+        "openvino_graph_builder_test", 
+        "openvino_delegate_core_test",
+        "openvino_delegate_external_test",
+        "openvino_delegate_test",
+    ]
+)
diff --git a/tensorflow/lite/delegates/openvino/e2e_openvino_fp32_anisha.cpp b/tensorflow/lite/delegates/openvino/e2e_openvino_fp32_anisha.cpp
new file mode 100644
index 000000000000..6d89f2390ba6
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/e2e_openvino_fp32_anisha.cpp
@@ -0,0 +1,166 @@
+#include <openvino/openvino.hpp>
+#include <openvino/opsets/opset3.hpp>
+#include <openvino/pass/manager.hpp>
+#include <openvino/pass/serialize.hpp>
+#include <openvino/runtime/core.hpp>
+#include <cmath>
+
+int main() {
+	ov::Core ov_core;
+	std::shared_ptr<ov::Model> embedding_model = ov_core.read_model("embedding_fp32.xml");
+	std::cout << " Read model\n";
+	embedding_model->reshape({{25}});
+	ov::CompiledModel compiled_model = ov_core.compile_model(embedding_model, "CPU");
+	ov::InferRequest compiled_model_ireq = compiled_model.create_infer_request();
+	ov::Tensor embedding_tensor_0 = compiled_model_ireq.get_input_tensor(0);
+	
+	int input_embedding[25] = {2, 235368, 235292, 2439, 603, 573, 6037, 576, 6081, 235336, 586, 235292, 7127, 235269, 1274, 235292, 2439, 603, 573, 6037, 576, 9066, 15378, 586, 235292};
+	int* p_input_embedding = input_embedding;
+	// compiled_model_ireq.set_input_tensor(embedding_tensor_0,
+	int* embed_dest = embedding_tensor_0.data<int>();
+	std::memcpy((uint8_t *)embed_dest, (uint8_t *)p_input_embedding, 25 * 4);
+	compiled_model_ireq.infer();
+	//compiled_model_ireq.wait_for(std::chrono::milliseconds(10000));
+	std::cout << "infer done\n";
+	ov::Tensor embedding_tensor_op_0 = compiled_model_ireq.get_output_tensor(0);
+	float *result_embed = embedding_tensor_op_0.data<float>();
+	std::cout << " Result pointer read\n";
+	ov::Shape shape_embedding = embedding_tensor_op_0.get_shape();
+	int embedding_op_size = shape_embedding.size();
+	std::cout << "dest = " << embedding_op_size << "size " << shape_embedding[0] << " " << shape_embedding[1] << " values =";
+	/*for(int i = 0; i < 10; i++) {
+		std::cout << *(result + i) << " ";
+	}*/
+	 std::shared_ptr<ov::Model> prefix_0_qkv_model = ov_core.read_model("prefix_0_qkv_int.xml");
+        ov::CompiledModel compiled_model_prefix = ov_core.compile_model(prefix_0_qkv_model, "NPU");
+	ov::InferRequest compiled_model_ireq_prefix = compiled_model_prefix.create_infer_request();
+
+	 std::shared_ptr<ov::Model> prefix_0_model = ov_core.read_model("prefix_0_int.xml");
+        ov::CompiledModel compiled_model_prefix0 = ov_core.compile_model(prefix_0_model, "NPU");
+	ov::InferRequest compiled_model_ireq_prefix0 = compiled_model_prefix0.create_infer_request();
+
+	 std::shared_ptr<ov::Model> prefix_1_model = ov_core.read_model("prefix_1_int.xml");
+        ov::CompiledModel compiled_model_prefix1 = ov_core.compile_model(prefix_1_model, "NPU");
+	ov::InferRequest compiled_model_ireq_prefix1 = compiled_model_prefix1.create_infer_request();
+
+	 std::shared_ptr<ov::Model> prefix_2_model = ov_core.read_model("prefix_2_int.xml");
+        ov::CompiledModel compiled_model_prefix2 = ov_core.compile_model(prefix_2_model, "NPU");
+	ov::InferRequest compiled_model_ireq_prefix2 = compiled_model_prefix2.create_infer_request();
+
+	 std::shared_ptr<ov::Model> prefix_3_model = ov_core.read_model("prefix_3_int.xml");
+        ov::CompiledModel compiled_model_prefix3 = ov_core.compile_model(prefix_3_model, "NPU");
+	ov::InferRequest compiled_model_ireq_prefix3 = compiled_model_prefix3.create_infer_request();
+
+    ov::Tensor embedding_ip = compiled_model_ireq_prefix.get_input_tensor(6);
+    float_t *dest_1 = embedding_ip.data<float>();
+	memset(dest_1, 0, embedding_ip.get_byte_size());
+	memcpy((uint8_t*) dest_1, (uint8_t*)result_embed, embedding_tensor_op_0.get_byte_size());
+
+	float lora_weights[1536 * 32];
+	memset(lora_weights,  0, sizeof(lora_weights));
+	float* p_lr = lora_weights;
+    
+	/*ov::Tensor lr_q_l = compiled_model_ireq_prefix.get_input_tensor(0);//"prefix_0_qkv_lora_query_w_prime_left:0");
+    dest_1 = lr_q_l.data<float>();
+	auto val_0 = lr_q_l.get_byte_size();
+    std::memcpy((uint8_t *)dest_1, (uint8_t *)p_lr, sizeof(lora_weights));
+
+	ov::Tensor lr_v_r = compiled_model_ireq_prefix.get_input_tensor(1);//"prefix_0_qkv_lora_value_w_prime_right:0");
+    dest_1 = lr_v_r.data<float>();
+    std::memcpy((uint8_t *)dest_1, (uint8_t *)p_lr, sizeof(lora_weights));
+	auto val_1 = lr_v_r.get_byte_size();
+
+	/*ov::Tensor lr_q_r = compiled_model_ireq_prefix.get_input_tensor(2);//prefix_0_qkv_lora_query_w_prime_right:0");
+    dest_1 = lr_q_r.data<float>();
+    std::memcpy((uint8_t *)dest_1, (uint8_t *)p_lr, sizeof(lora_weights));
+	auto val_2 = lr_q_r.get_byte_size();
+
+	ov::Tensor lr_k_l = compiled_model_ireq_prefix.get_input_tensor(3);//prefix_0_qkv_lora_key_w_prime_left:0");
+    dest_1 = lr_k_l.data<float>();
+    std::memcpy((uint8_t *)dest_1, (uint8_t *)p_lr, sizeof(lora_weights));
+	auto val_3 = lr_k_l.get_byte_size();
+
+	ov::Tensor lr_k_r = compiled_model_ireq_prefix.get_input_tensor(5);//"prefix_0_qkv_lora_key_w_prime_right:0");
+    dest_1 = lr_k_r.data<float>();
+    std::memcpy((uint8_t *)dest_1, (uint8_t *)p_lr, sizeof(lora_weights));
+	auto val_5 = lr_k_r.get_byte_size();
+	ov::Tensor lr_v_l = compiled_model_ireq_prefix.get_input_tensor(8);//"prefix_0_qkv_lora_value_w_prime_left:0");
+    dest_1 = lr_v_l.data<float>();
+    std::memcpy((uint8_t *)dest_1, (uint8_t *)p_lr, sizeof(lora_weights));
+	auto val_8 = lr_v_l.get_byte_size();*/
+
+	// Build RoPE tensors 
+	float rope_cos[128][1][128];
+    float rope_sin[128][1][128];
+    float atten_mask[128][128];
+    for (int i = 0; i < 128; i++) {
+        for (int j = 0; j < 128; j++){
+            //rope_cos[i][0][j] = (float)std::cos(i/pow(10000,j*(2/256)));
+            //rope_sin[i][0][j] = (float)std::sin(i/pow(10000,j*(2/256)));
+			if ( i <= j ) {
+				atten_mask[i][j] = 0;
+			} else {
+				atten_mask[i][j] = -std::numeric_limits<float>::max();
+			}
+		}
+    }
+	float rope_cos_single_arr[128 * 128];
+	float rope_sin_single_arr[128 * 128];
+	int k = 0;
+	for (int i = 0; i < 128; i++) {
+			for (int j = 0; j < 128; j++){
+				rope_cos_single_arr[k] = rope_cos[i][0][j];
+				rope_sin_single_arr[k] = rope_sin[i][0][j];
+				k++;
+			}
+	}
+
+    ov::Tensor rope_cos_input = compiled_model_ireq_prefix.get_input_tensor(4); //"prefix_0_qkv_positional_cos:0");
+    uint8_t  *dest_rope = (uint8_t*)rope_cos_input.data<float>();
+	float* p_rope = rope_cos_single_arr;
+    std::memcpy((uint8_t*)dest_rope, (uint8_t*)p_rope, sizeof(rope_cos_single_arr));
+
+
+    ov::Tensor rope_sin_input = compiled_model_ireq_prefix.get_input_tensor(7); //"prefix_0_qkv_positional_sin:0");
+    dest_rope = (uint8_t*)rope_sin_input.data<float>();
+	p_rope = rope_sin_single_arr;
+    std::memcpy((uint8_t*)dest_rope, (uint8_t*)p_rope, sizeof(rope_sin_single_arr));
+	//compiled_model_ireq_prefix.set_input_tensor(6, embedding_tensor_op_0);*/
+	compiled_model_ireq_prefix.infer();
+	//	compiled_model_ireq_prefix.wait_for(std::chrono::milliseconds(10000000));
+	ov::Tensor prefix_0_qkv_op_0 = compiled_model_ireq_prefix.get_output_tensor(0);
+	float *result = prefix_0_qkv_op_0.data<float>();
+	ov::Shape shape_pre_0_qkv = prefix_0_qkv_op_0.get_shape();
+	std::cout << "dest = " << shape_pre_0_qkv.size() << "size " << shape_pre_0_qkv[0] << " " << shape_pre_0_qkv[1] << " values =";
+	for(int i = 0; i < 10; i++) {
+		std::cout << *(result + i) << " ";
+	}
+
+	ov::Tensor inputBlobprefix0 = compiled_model_ireq_prefix.get_output_tensor(0);
+	std::cout << "compiled_model_ireq_prefix0 size = " << inputBlobprefix0.get_byte_size() << "\n";
+	uint8_t *src = (uint8_t *)inputBlobprefix0.data<float>();
+	ov::Tensor inputBlob = compiled_model_ireq_prefix0.get_input_tensor(7);
+	std::cout << "compiled_model_ireq_prefix0 size = " << inputBlob.get_byte_size() << "\n";
+	uint8_t *dest = (uint8_t *)inputBlob.data<float>();
+
+	std::memcpy((uint8_t *)dest, (uint8_t *)src, inputBlob.get_byte_size());
+	compiled_model_ireq_prefix0.infer();
+	std::cout << "prefix0 done " << "\n";
+	
+	ov::Tensor inputBlobprefix1 = compiled_model_ireq_prefix0.get_output_tensor(0);
+	std::cout << "compiled_model_ireq_prefix0 size = " << inputBlobprefix0.get_byte_size() << "\n";
+	uint8_t *src1 = (uint8_t *)inputBlobprefix1.data<float>();
+	ov::Tensor inputBlob1 = compiled_model_ireq_prefix1.get_input_tensor(7);
+	std::cout << "compiled_model_ireq_prefix0 size = " << inputBlob.get_byte_size() << "\n";
+	uint8_t *dest1 = (uint8_t *)inputBlob1.data<float>();
+	std::memcpy((uint8_t *)dest1, (uint8_t *)src1, inputBlob1.get_byte_size());
+	
+	compiled_model_ireq_prefix1.infer();
+	std::cout << "prefix1 done " << "\n";
+
+	compiled_model_ireq_prefix2.infer();
+	std::cout << "prefix2 done " << "\n";
+	compiled_model_ireq_prefix3.infer();
+	std::cout << "prefix3	\n";// val_0 << " " << val_1 << " " << val_2 << " " << val_3 << " " << val_5 << " " << val_8 << "\n";
+	return 1;
+}
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate.cc b/tensorflow/lite/delegates/openvino/openvino_delegate.cc
new file mode 100644
index 000000000000..7b3eb0543349
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate.cc
@@ -0,0 +1,233 @@
+/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+#include "openvino_delegate.h"
+
+#include "openvino/runtime/core.hpp"
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/builtin_op_data.h"
+#include "tensorflow/lite/c/c_api.h"
+#include "tensorflow/lite/c/c_api_opaque.h"
+#include "tensorflow/lite/c/c_api_types.h"
+#include "tensorflow/lite/c/common.h"
+#include "tensorflow/lite/delegates/utils/simple_opaque_delegate.h"
+
+namespace tflite {
+namespace openvinodelegate {
+bool OpenVINODelegate::CheckInputsType(const int tensor_id, const TfLiteOpaqueContext *context,
+                                       TfLiteType expected_type) const {
+    const TfLiteOpaqueTensor *opaque_tensor =
+        TfLiteOpaqueContextGetOpaqueTensor(context, tensor_id);
+    TfLiteType type = TfLiteOpaqueTensorType(opaque_tensor);
+    return expected_type == type;
+}
+
+bool OpenVINODelegate::CheckDataTypeSupported(
+    const TfLiteOpaqueContext *context, const TfLiteOpaqueNode *node,
+    std::vector<std::vector<TfLiteType>> supported_types) const {
+    const int *inputs;
+    int num_inputs;
+    auto tf_status = TfLiteOpaqueNodeInputs(node, &inputs, &num_inputs);
+    for (int i = 0; i < supported_types.size(); i++) {
+        int tensor_id = inputs[i];
+        bool supported = false;
+        for (TfLiteType type : supported_types[i])
+            supported = CheckInputsType(tensor_id, context, type);
+        if (supported == false) return false;
+    }
+    return true;
+}
+
+bool OpenVINODelegate::CheckDims(const TfLiteOpaqueContext *context, const TfLiteOpaqueNode *node,
+                                 std::vector<std::vector<int>> dims_size) const {
+    const int *inputs;
+    int num_inputs;
+    bool supported;
+    auto tf_status = TfLiteOpaqueNodeInputs(node, &inputs, &num_inputs);
+    if (num_inputs != dims_size.size()) return false;
+    for (int i = 0; i < dims_size.size(); i++) {
+        supported = false;
+        const TfLiteOpaqueTensor *opaque_tensor =
+            TfLiteOpaqueContextGetOpaqueTensor(context, inputs[i]);
+        for (int j = 0; j < dims_size[i].size(); j++) {
+            if (TfLiteOpaqueTensorNumDims(opaque_tensor) == dims_size[i][j]) {
+                supported = true;
+                int size = 1;
+                for (int k = 0; k < dims_size[i][j]; k++)
+                    size *= TfLiteOpaqueTensorDim(opaque_tensor, k);
+                if (size == 0) return false;
+            }
+        }
+        if (supported == false) return false;
+    }
+    return supported;
+}
+
+bool OpenVINODelegate::CheckNodeSupportByOpenVINO(const TfLiteRegistrationExternal *registration,
+                                                  const TfLiteOpaqueNode *node,
+                                                  TfLiteOpaqueContext *context) const {
+    switch (TfLiteRegistrationExternalGetBuiltInCode(registration)) {
+        case kTfLiteBuiltinAdd: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                   CheckDims(context, node, {{1, 2, 3, 4}, {1, 2, 3, 4}});
+        }
+        case kTfLiteBuiltinAveragePool2d: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinConv2d: {
+            const int *inputs;
+            int num_inputs;
+            auto tf_status = TfLiteOpaqueNodeInputs(node, &inputs, &num_inputs);
+            if (num_inputs == 2) {
+                return CheckDataTypeSupported(context, node,
+                                              {{kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                       CheckDims(context, node, {{4}, {4}});
+            } else if (num_inputs == 3) {
+                return CheckDataTypeSupported(
+                           context, node, {{kTfLiteFloat32}, {kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                       CheckDims(context, node, {{4}, {4}, {1}});
+            } else
+                return false;
+        }
+        case kTfLiteBuiltinConcatenation: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                   CheckDims(context, node, {{4}, {4}});
+        }
+        case kTfLiteBuiltinCustom: {
+            if (strcmp(TfLiteRegistrationExternalGetCustomName(registration),
+                       "Convolution2DTransposeBias") == 0) {
+                return CheckDataTypeSupported(
+                           context, node, {{kTfLiteFloat32}, {kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                       CheckDims(context, node, {{4}, {4}, {1}});
+            }
+            return false;
+        }
+        case kTfLiteBuiltinDepthwiseConv2d: {
+            const int *inputs;
+            int num_inputs;
+            auto tf_status = TfLiteOpaqueNodeInputs(node, &inputs, &num_inputs);
+            if (num_inputs == 2) {
+                return CheckDataTypeSupported(context, node,
+                                              {{kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                       CheckDims(context, node, {{4}, {4}});
+            } else if (num_inputs == 3) {
+                return CheckDataTypeSupported(
+                           context, node, {{kTfLiteFloat32}, {kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                       CheckDims(context, node, {{4}, {4}, {1}});
+            } else
+                return false;
+        }
+        case kTfLiteBuiltinDequantize: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat16}});
+        }
+        case kTfLiteBuiltinResizeBilinear: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinRelu: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinRelu6: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinLogistic: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinHardSwish: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinMul: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                   CheckDims(context, node, {{1, 2, 3, 4}, {1, 2, 3, 4}});
+        }
+        case kTfLiteBuiltinSoftmax: {
+            TfLiteSoftmaxParams *softmax_params =
+                (TfLiteSoftmaxParams *)TfLiteOpaqueNodeGetBuiltinData(node);
+            if (softmax_params->beta != 1.0f) {
+                TFLITE_LOG(INFO) << "Unsupported Softmax op, beta value is not 1.0 \n";
+                return false;
+            }
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinTanh: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinReshape: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}, {kTfLiteInt32}}) &&
+                   CheckDims(context, node, {{1, 2, 3, 4}, {1}});
+        }
+        case kTfLiteBuiltinMaxPool2d: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}});
+        }
+        case kTfLiteBuiltinMean: {
+            return CheckDataTypeSupported(context, node, {{kTfLiteFloat32}}) &&
+                   CheckDims(context, node, {{4}, {1}});
+        }
+        case kTfLiteBuiltinTransposeConv: {
+            const int *inputs_data;
+            int num_inputs;
+            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+            if (num_inputs == 3) {
+                return CheckDataTypeSupported(
+                           context, node, {{kTfLiteInt32}, {kTfLiteFloat32}, {kTfLiteFloat32}}) &&
+                       CheckDims(context, node, {{1}, {4}, {4}});
+            } else if (num_inputs == 4) {
+                return CheckDataTypeSupported(context, node,
+                                              {{kTfLiteInt32},
+                                               {kTfLiteFloat32},
+                                               {kTfLiteFloat32},
+                                               {kTfLiteFloat32}}) &&
+                       CheckDims(context, node, {{1}, {4}, {4}, {1}});
+            } else {
+                return false;
+            }
+        }
+        default:
+            return false;
+    }
+}
+
+bool OpenVINODelegate::IsNodeSupportedByDelegate(const TfLiteRegistrationExternal *registration,
+                                                 const TfLiteOpaqueNode *node,
+                                                 TfLiteOpaqueContext *context) const {
+    if (registration == nullptr || node == nullptr || context == nullptr) return false;
+    bool check = CheckNodeSupportByOpenVINO(registration, node, context);
+    return check;
+}
+
+TfLiteStatus OpenVINODelegate::Initialize(TfLiteOpaqueContext *context) { return kTfLiteOk; }
+
+const char *OpenVINODelegate::Name() const { return "OpenVINO SimpleOpaqueDelegate"; }
+
+std::unique_ptr<tflite::SimpleOpaqueDelegateKernelInterface>
+OpenVINODelegate::CreateDelegateKernelInterface() {
+    return std::unique_ptr<tflite::openvinodelegate::OpenVINODelegateKernel>(
+        new tflite::openvinodelegate::OpenVINODelegateKernel());
+}
+}  // namespace openvinodelegate
+}  // namespace tflite
+
+TfLiteDelegate *TFL_CAPI_EXPORT
+TfLiteCreateOpenVINODelegate(const TfLiteOpenVINODelegateOptions *options) {
+    auto ovdelegate_ = std::make_unique<tflite::openvinodelegate::OpenVINODelegate>(options);
+    return tflite::TfLiteOpaqueDelegateFactory::CreateSimpleDelegate(std::move(ovdelegate_));
+}
+
+void TFL_CAPI_EXPORT TfLiteDeleteOpenVINODelegate(TfLiteOpaqueDelegate *delegate) { return; }
+
+TfLiteOpenVINODelegateOptions TFL_CAPI_EXPORT TfLiteOpenVINODelegateOptionsDefault() {
+    TfLiteOpenVINODelegateOptions result;
+    result.debug_level = 0;
+    result.plugins_path = "/tmp/plugins.xml";
+    return result;
+}
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate.h b/tensorflow/lite/delegates/openvino/openvino_delegate.h
new file mode 100644
index 000000000000..fe0166dbf2c6
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate.h
@@ -0,0 +1,91 @@
+/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_H_
+
+#include "openvino_delegate_kernel.h"
+#include "tensorflow/lite/c/common.h"
+#include "tensorflow/lite/delegates/utils/simple_opaque_delegate.h"
+
+#ifdef __cplusplus
+extern "C" {
+#endif  // __cplusplus
+
+static const char kOpenVINOStableDelegateName[] = "intel_openvino_delegate";
+static const char kOpenVINOStableDelegateVersion[] = "1.0.0";
+
+struct TFL_CAPI_EXPORT TfLiteOpenVINODelegateOptions {
+    /* debug_level for the OpenVINO delegate*/
+    int debug_level;
+
+    /* path for the OpenVINO plugins */
+    char *plugins_path;
+
+    /* Device for OpenVINO to select
+        Currently we support CPU and NPU
+    char* device_type*/
+    ;
+};
+
+TfLiteOpenVINODelegateOptions TFL_CAPI_EXPORT TfLiteOpenVINODelegateOptionsDefault();
+
+TfLiteOpaqueDelegate *TFL_CAPI_EXPORT
+TfLiteCreateOpenVINODelegate(const TfLiteOpenVINODelegateOptions *options);
+
+void TFL_CAPI_EXPORT TfLiteDeleteOpenVINODelegate(TfLiteOpaqueDelegate *delegate);
+
+namespace tflite {
+namespace openvinodelegate {
+
+// forward declaration
+class OpenVINODelegateTestPeer;
+
+class OpenVINODelegate : public SimpleOpaqueDelegateInterface {
+public:
+    explicit OpenVINODelegate(const TfLiteOpenVINODelegateOptions *options) : options_(*options) {
+        if (options == nullptr) options_ = TfLiteOpenVINODelegateOptionsDefault();
+    }
+
+    bool IsNodeSupportedByDelegate(const TfLiteRegistrationExternal *registration,
+                                   const TfLiteOpaqueNode *node,
+                                   TfLiteOpaqueContext *context) const override;
+
+    TfLiteStatus Initialize(TfLiteOpaqueContext *context) override;
+
+    const char *Name() const override;
+
+    std::unique_ptr<SimpleOpaqueDelegateKernelInterface> CreateDelegateKernelInterface() override;
+
+private:
+    TfLiteOpenVINODelegateOptions options_;
+    friend class OpenVINODelegateTestPeer;
+    bool CheckInputsType(const int tensor_id, const TfLiteOpaqueContext *context,
+                         TfLiteType expected_type) const;
+    bool CheckDataTypeSupported(const TfLiteOpaqueContext *context, const TfLiteOpaqueNode *node,
+                                std::vector<std::vector<TfLiteType>> supported_types) const;
+    bool CheckDims(const TfLiteOpaqueContext *context, const TfLiteOpaqueNode *node,
+                   std::vector<std::vector<int>> dims_size) const;
+    bool CheckNodeSupportByOpenVINO(const TfLiteRegistrationExternal *registration,
+                                    const TfLiteOpaqueNode *node,
+                                    TfLiteOpaqueContext *context) const;
+};
+}  // namespace openvinodelegate
+}  // namespace tflite
+
+#ifdef __cplusplus
+}
+#endif  // __cplusplus
+
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_H_
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_adapter.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_adapter.cc
new file mode 100644
index 000000000000..b43695260114
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_adapter.cc
@@ -0,0 +1,64 @@
+#include <string>
+#include <vector>
+
+#include "tensorflow/lite/delegates/external/external_delegate_interface.h"
+#include "tensorflow/lite/delegates/openvino/openvino_delegate.h"
+#include "tensorflow/lite/tools/command_line_flags.h"
+
+TfLiteDelegate *CreateOVDelegateFromOptions(const char *const *options_keys,
+                                            const char *const *options_values, size_t num_options) {
+    TfLiteOpenVINODelegateOptions options = TfLiteOpenVINODelegateOptionsDefault();
+    std::vector<const char *> argv;
+    int argc = num_options + 1;
+    argv.reserve(num_options + 1);
+    std::vector<std::string> option_args;
+    option_args.reserve(num_options);
+    for (int i = 0; i < num_options; i++) {
+        option_args.emplace_back("--");
+        option_args.rbegin()->append(options_keys[i]);
+        option_args.rbegin()->append("=");
+        option_args.rbegin()->append(options_values[i]);
+        argv.push_back(option_args.rbegin()->c_str());
+    }
+
+    constexpr char kDebugLevel[] = "debug_level";
+    constexpr char kPluginsPath[] = "plugins_path";
+    constexpr char kDeviceType[] = "device_type";
+
+    std::vector<tflite::Flag> flag_list = {
+        tflite::Flag::CreateFlag(kDebugLevel, &options.debug_level,
+                                 "Debug Level for OpenVINO delegate."),
+        /*tflite::Flag::CreateFlag(kPluginsPath,
+                                 &options.plugins_path,
+                                 "Plugins.xml path.")
+        /*tflite::Flag::CreateFlag(kDeviceType,
+                                 &options.device_type,
+                                 "Device Type."), */
+    };
+
+    if (!tflite::Flags::Parse(&argc, argv.data(), flag_list)) {
+        return nullptr;
+    }
+
+    TFLITE_LOG(INFO) << "OpenVINO delegate: debug_level set to " << options.debug_level << ".";
+    /* TFLITE_LOG(INFO) << "OpenVINO delegate: plugins_path set to "
+                     << options.plugins_path << ".";
+    TFLITE_LOG(INFO) << "OpenVINO delegate: device_type set to "
+                     << options.device_type << "."; */
+
+    return TfLiteCreateOpenVINODelegate(&options);
+}
+
+extern "C" {
+
+// Defines two symbols that need to be exported to use the TFLite external
+// delegate. See tensorflow/lite/delegates/external for details.
+extern TFL_EXTERNAL_DELEGATE_EXPORT TfLiteDelegate *tflite_plugin_create_delegate(
+    const char *const *options_keys, const char *const *options_values, size_t num_options,
+    void (*report_error)(const char *)) {
+    return CreateOVDelegateFromOptions(options_keys, options_values, num_options);
+}
+
+TFL_EXTERNAL_DELEGATE_EXPORT void tflite_plugin_destroy_delegate(TfLiteDelegate *delegate) {}
+
+}  // extern "C"
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_builder_test.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_builder_test.cc
new file mode 100644
index 000000000000..d3de52759c12
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_builder_test.cc
@@ -0,0 +1,101 @@
+#include <gtest/gtest.h>
+
+#include "openvino_graph_builder.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TEST(AddInputParams, checkInvalidDims) {
+    const std::vector<int> x = {};
+    TfLiteIntArray *lite = TfLiteIntArrayCreate(x.size());
+    for (size_t i = 0; i < x.size(); i++) lite->data[i] = x[i];
+
+    TfLiteTensor t_ptr;
+    t_ptr.dims = lite;
+    std::unique_ptr<OpenVINOGraphBuilder> graph_builder_test =
+        std::make_unique<OpenVINOGraphBuilder>(std::make_unique<NodeManager>());
+    EXPECT_EQ(graph_builder_test->AddInputParams(t_ptr, 1), kTfLiteError);
+    TfLiteIntArrayFree(lite);
+}
+
+TEST(AddInputParams, checkValidDims) {
+    TfLiteIntArray t;
+    const std::vector<int> x = {1, 3, 3, 2};
+    TfLiteIntArray *lite = TfLiteIntArrayCreate(x.size());
+    for (size_t i = 0; i < x.size(); i++) lite->data[i] = x[i];
+
+    TfLiteTensor t_ptr;
+    t_ptr.dims = lite;
+    std::unique_ptr<OpenVINOGraphBuilder> graph_builder_test =
+        std::make_unique<OpenVINOGraphBuilder>(std::make_unique<NodeManager>());
+    EXPECT_EQ(graph_builder_test->AddInputParams(t_ptr, 1), kTfLiteOk);
+    TfLiteIntArrayFree(lite);
+}
+
+TEST(AddInputParams, checkNodeState) {
+    TfLiteIntArray t;
+    const std::vector<int> x = {1, 3, 3, 2};
+    TfLiteIntArray *lite = TfLiteIntArrayCreate(x.size());
+    for (size_t i = 0; i < x.size(); i++) lite->data[i] = x[i];
+
+    TfLiteTensor t_ptr;
+    t_ptr.dims = lite;
+    std::unique_ptr<OpenVINOGraphBuilder> graph_builder =
+        std::make_unique<OpenVINOGraphBuilder>(std::make_unique<NodeManager>());
+    EXPECT_EQ(graph_builder->AddInputParams(t_ptr, 1), kTfLiteOk);
+    EXPECT_EQ(graph_builder->getNodeManagerSize() == 1, true);
+    TfLiteIntArrayFree(lite);
+}
+
+TEST(CreateConstNode, checkInvalidDims) {
+    TfLiteIntArray t;
+    const std::vector<int> x = {};
+    TfLiteIntArray *lite = TfLiteIntArrayCreate(x.size());
+    for (size_t i = 0; i < x.size(); i++) lite->data[i] = x[i];
+
+    TfLiteTensor t_ptr;
+    t_ptr.dims = lite;
+    std::unique_ptr<OpenVINOGraphBuilder> graph_builder_test =
+        std::make_unique<OpenVINOGraphBuilder>(std::make_unique<NodeManager>());
+    EXPECT_EQ(graph_builder_test->CreateConstNode(t_ptr, 1), kTfLiteError);
+    TfLiteIntArrayFree(lite);
+}
+
+TEST(CreateConstNode, checkNullConstData) {
+    TfLiteIntArray t;
+    const std::vector<int> x = {1, 3, 3, 2};
+    TfLiteIntArray *lite = TfLiteIntArrayCreate(x.size());
+    for (size_t i = 0; i < x.size(); i++) lite->data[i] = x[i];
+    TfLitePtrUnion tensor_data;
+    tensor_data.raw_const = nullptr;
+    TfLiteTensor t_ptr;
+    t_ptr.dims = lite;
+    t_ptr.data = tensor_data;
+    std::unique_ptr<OpenVINOGraphBuilder> graph_builder_test =
+        std::make_unique<OpenVINOGraphBuilder>(std::make_unique<NodeManager>());
+    EXPECT_EQ(graph_builder_test->CreateConstNode(t_ptr, 1), kTfLiteError);
+    TfLiteIntArrayFree(lite);
+}
+
+TEST(CreateConstNode, checkNodeState) {
+    TfLiteIntArray t;
+    const std::vector<int> x = {1, 3, 3, 3};
+    TfLiteIntArray *lite = TfLiteIntArrayCreate(x.size());
+    for (size_t i = 0; i < x.size(); i++) lite->data[i] = x[i];
+    TfLitePtrUnion tensor_data;
+    float float_data[3][3][3] = {{{1.0, 2.0, 3.0}, {1.0, 2.0, 3.0}, {1.0, 2.0, 3.0}},
+                                 {{1.0, 2.0, 3.0}, {1.0, 2.0, 3.0}, {1.0, 2.0, 3.0}},
+                                 {{1.0, 2.0, 3.0}, {1.0, 2.0, 3.0}, {1.0, 2.0, 3.0}}};
+    tensor_data.raw_const = (const char *)&float_data;
+    TfLiteTensor t_ptr;
+    t_ptr.dims = lite;
+    t_ptr.data = tensor_data;
+    std::unique_ptr<OpenVINOGraphBuilder> graph_builder =
+        std::make_unique<OpenVINOGraphBuilder>(std::make_unique<NodeManager>());
+    EXPECT_EQ(graph_builder->CreateConstNode(t_ptr, 1), kTfLiteOk);
+    EXPECT_EQ(graph_builder->getNodeManagerSize() == 1, true);
+    TfLiteIntArrayFree(lite);
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_core.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_core.cc
new file mode 100644
index 000000000000..a96973278184
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_core.cc
@@ -0,0 +1,80 @@
+// openvino_graph_builder.cc
+#include "openvino_delegate_core.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus OpenVINODelegateCore::CreateGraphfromTfLite(TfLiteOpaqueContext *context,
+                                                         const TfLiteOpaqueDelegateParams *params) {
+    if (context == nullptr || params == nullptr) return kTfLiteError;
+    const std::unordered_set<int> inputs(&params->input_tensors->data[0],
+                                         &params->input_tensors->data[params->input_tensors->size]);
+
+    openvino_graph_builder_ =
+        std::make_unique<OpenVINOGraphBuilder>(std::make_unique<NodeManager>());
+
+    for (int o = 0; o < params->output_tensors->size; o++) {
+        const int output_tensor_idx = params->output_tensors->data[o];
+        outputs_.push_back(output_tensor_idx);
+    }
+
+    for (int i = 0; i < params->nodes_to_replace->size; i++) {
+        const int delegate_node_id = params->nodes_to_replace->data[i];
+        TfLiteOpaqueNode *delegate_node;
+        TfLiteRegistrationExternal *delegate_node_registration;
+        if (TfLiteOpaqueContextGetNodeAndRegistration(context, delegate_node_id, &delegate_node,
+                                                      &delegate_node_registration))
+            return kTfLiteError;
+
+        int inputs_size = TfLiteOpaqueNodeNumberOfInputs(delegate_node);
+        for (int k = 0; k < inputs_size; k++) {
+            if (TfLiteRegistrationExternalGetBuiltInCode(delegate_node_registration) ==
+                    kTfLiteBuiltinTransposeConv &&
+                k == 0) {
+                continue;
+            }
+            const int *inputs_data = nullptr;
+            int num_inputs = 0;
+            TfLiteStatus tf_status =
+                TfLiteOpaqueNodeInputs(delegate_node, &inputs_data, &num_inputs);
+            const int t = inputs_data[k];
+            const void *data = nullptr;
+            auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(context, t);
+            auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+            if (allocation_type == kTfLiteMmapRo) {
+                data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                if (openvino_graph_builder_->CreateConstNode(context, t) != kTfLiteOk)
+                    return kTfLiteError;
+            }
+            if (inputs.count(t) != 0) {
+                if (data == nullptr) {
+                    if (openvino_graph_builder_->AddInputParams(opaque_tensor, t) != kTfLiteOk)
+                        return kTfLiteError;
+                    compute_inputs_.push_back(t);
+                }
+            }
+        }
+        if (openvino_graph_builder_->CreateNodeFromTfLiteOp(
+                delegate_node_id, delegate_node_registration, delegate_node, context) != kTfLiteOk)
+            return kTfLiteError;
+    }
+
+    openvino_graph_builder_->UpdateResultNodes(context, outputs_);
+    std::shared_ptr<ov::Model> model = std::make_shared<ov::Model>(
+        openvino_graph_builder_->getResultNodes(), openvino_graph_builder_->getInputParams());
+    // TODO: get device string from flags
+    std::string deviceStr = "CPU";
+    if (model) {
+        compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+        ov::pass::Manager manager;
+        manager.register_pass<ov::pass::Serialize>("model.xml", "model.bin");
+        manager.run_passes(model);
+    }
+
+    infer_request_ = compiled_model_.create_infer_request();
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_core.h b/tensorflow/lite/delegates/openvino/openvino_delegate_core.h
new file mode 100644
index 000000000000..f5bcace11abc
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_core.h
@@ -0,0 +1,51 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_CORE_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_CORE_H_
+#include <iostream>
+#include <vector>
+
+#include <openvino/openvino.hpp>
+#include <openvino/pass/manager.hpp>
+#include <openvino/pass/serialize.hpp>
+#include <openvino/runtime/core.hpp>
+#include "openvino_graph_builder.h"
+#include "operations/openvino_node_manager.h"
+
+namespace tflite {
+namespace openvinodelegate {
+class OpenVINODelegateCore {
+public:
+    OpenVINODelegateCore(std::string_view plugins_path) : openvino_delegate_core_(ov::Core()) {
+        plugins_location_ = plugins_path;
+    }
+    TfLiteStatus OpenVINODelegateInit() {
+        std::vector<std::string> ov_devices = openvino_delegate_core_.get_available_devices();
+        if (std::find(ov_devices.begin(), ov_devices.end(), "CPU") == ov_devices.end()) {
+            return kTfLiteDelegateError;
+        } else {
+            return kTfLiteOk;
+        }
+    }
+
+    std::vector<int> getComputeInputs() { return compute_inputs_; }
+
+    std::vector<int> getOutputs() { return outputs_; }
+
+    ov::InferRequest getInferRequest() const { return infer_request_; }
+
+    TfLiteStatus CreateGraphfromTfLite(TfLiteOpaqueContext *context,
+                                       const TfLiteOpaqueDelegateParams *params);
+
+private:
+    std::unique_ptr<OpenVINOGraphBuilder> openvino_graph_builder_;
+    ov::Core openvino_delegate_core_;
+    std::string plugins_location_;
+    std::shared_ptr<ov::Model> model_;
+    ov::CompiledModel compiled_model_;
+    std::string ov_device_ = "CPU";
+    std::vector<int> compute_inputs_ = {};
+    std::vector<int> outputs_ = {};
+    ov::InferRequest infer_request_;
+};
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_KERNEL_H_
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_core_test.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_core_test.cc
new file mode 100644
index 000000000000..cfbfc161de77
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_core_test.cc
@@ -0,0 +1,135 @@
+#include "openvino_delegate_core.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include "openvino_graph_builder.h"
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/c_api.h"
+#include "tensorflow/lite/core/kernels/builtin_op_kernels.h"
+#include "tensorflow/lite/interpreter.h"
+#include "tensorflow/lite/interpreter_builder.h"
+#include "tensorflow/lite/kernels/kernel_util.h"
+
+class OpenVINODelegateCoreTest : public testing::Test {
+protected:
+    TfLiteInterpreter* interpreter_ = nullptr;
+    TfLiteOpaqueDelegate* opaque_delegate_ = nullptr;
+    TfLiteModel* model_ = nullptr;
+};
+
+TEST_F(OpenVINODelegateCoreTest, CreateGraphfromTfLite) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext* opaque_context,
+                                         TfLiteOpaqueDelegate* opaque_delegate_,
+                                         void* data) -> TfLiteStatus {
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext* opaque_context, const char* buffer, size_t length) -> void* {
+                const TfLiteOpaqueDelegateParams* params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams*>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                auto ov_delegate_core_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINODelegateCore>("");
+                EXPECT_EQ(kTfLiteOk, ov_delegate_core_test->OpenVINODelegateInit());
+                EXPECT_EQ(kTfLiteOk,
+                          ov_delegate_core_test->CreateGraphfromTfLite(opaque_context, params));
+                void* void_fake_ptr;
+                return void_fake_ptr;
+            });
+        return kTfLiteOk;
+    };
+
+    model_ = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+    opaque_delegate_ = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions* options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate_);
+    interpreter_ = TfLiteInterpreterCreate(model_, options);
+    ;
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter_);
+    TfLiteModelDelete(model_);
+    TfLiteOpaqueDelegateDelete(opaque_delegate_);
+}
+
+TEST_F(OpenVINODelegateCoreTest, CreateGraphfromTfLite_InvalidContext) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext* opaque_context,
+                                         TfLiteOpaqueDelegate* opaque_delegate_,
+                                         void* data) -> TfLiteStatus {
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext* opaque_context, const char* buffer, size_t length) -> void* {
+                const TfLiteOpaqueDelegateParams* params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams*>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                // test for context with null ptr
+                opaque_context == nullptr;
+                auto ov_delegate_core_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINODelegateCore>("");
+                EXPECT_EQ(kTfLiteOk, ov_delegate_core_test->OpenVINODelegateInit());
+                EXPECT_EQ(kTfLiteError,
+                          ov_delegate_core_test->CreateGraphfromTfLite(opaque_context, params));
+                void* void_fake_ptr;
+                return void_fake_ptr;
+            });
+        return kTfLiteOk;
+    };
+
+    model_ = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+    opaque_delegate_ = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions* options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate_);
+    interpreter_ = TfLiteInterpreterCreate(model_, options);
+    ;
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter_);
+    TfLiteModelDelete(model_);
+    TfLiteOpaqueDelegateDelete(opaque_delegate_);
+}
+
+TEST_F(OpenVINODelegateCoreTest, CreateGraphfromTfLite_InvalidParams) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext* opaque_context,
+                                         TfLiteOpaqueDelegate* opaque_delegate_,
+                                         void* data) -> TfLiteStatus {
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext* opaque_context, const char* buffer, size_t length) -> void* {
+                // test for params with null ptr
+                const TfLiteOpaqueDelegateParams* params = nullptr;
+                auto ov_delegate_core_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINODelegateCore>("");
+                EXPECT_EQ(kTfLiteOk, ov_delegate_core_test->OpenVINODelegateInit());
+                EXPECT_EQ(kTfLiteError,
+                          ov_delegate_core_test->CreateGraphfromTfLite(opaque_context, params));
+                void* void_fake_ptr;
+                return void_fake_ptr;
+            });
+        return kTfLiteOk;
+    };
+
+    model_ = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+    opaque_delegate_ = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions* options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate_);
+    interpreter_ = TfLiteInterpreterCreate(model_, options);
+    ;
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter_);
+    TfLiteModelDelete(model_);
+    TfLiteOpaqueDelegateDelete(opaque_delegate_);
+}
\ No newline at end of file
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_external.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_external.cc
new file mode 100644
index 000000000000..096c671fa9e4
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_external.cc
@@ -0,0 +1,53 @@
+/* Copyright 2022 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+#include <memory>
+#include <utility>
+
+#include "openvino_delegate.h"
+#include "tensorflow/lite/acceleration/configuration/c/delegate_plugin.h"
+#include "tensorflow/lite/acceleration/configuration/c/stable_delegate.h"
+#include "tensorflow/lite/c/c_api_types.h"
+#include "tensorflow/lite/c/common.h"
+#include "tensorflow/lite/delegates/utils/experimental/stable_delegate/stable_delegate_interface.h"
+#include "tensorflow/lite/delegates/utils/simple_opaque_delegate.h"
+
+namespace {
+
+TfLiteOpaqueDelegate *OpenVINOStableDelegateCreateFunc(const void *tflite_settings) {
+    TfLiteOpenVINODelegateOptions options = TfLiteOpenVINODelegateOptionsDefault();
+    auto delegate = std::make_unique<tflite::openvinodelegate::OpenVINODelegate>(&options);
+    return tflite::TfLiteOpaqueDelegateFactory::CreateSimpleDelegate(std::move(delegate));
+}
+
+void OpenVINOStableDelegateDestroyFunc(TfLiteOpaqueDelegate *openvino_stable_delegate) {
+    tflite::TfLiteOpaqueDelegateFactory::DeleteSimpleDelegate(openvino_stable_delegate);
+}
+
+int OpenVINOStableDelegateErrnoFunc(TfLiteOpaqueDelegate *openvino_stable_delegate) {
+    // no-op
+    return 0;
+}
+
+const TfLiteOpaqueDelegatePlugin openvino_stable_delegate_plugin = {
+    OpenVINOStableDelegateCreateFunc, OpenVINOStableDelegateDestroyFunc,
+    OpenVINOStableDelegateErrnoFunc};
+
+const TfLiteStableDelegate openvino_stable_delegate = {
+    TFL_STABLE_DELEGATE_ABI_VERSION, kOpenVINOStableDelegateName, kOpenVINOStableDelegateVersion,
+    &openvino_stable_delegate_plugin};
+
+}  // namespace
+
+extern "C" const TfLiteStableDelegate TFL_TheStableDelegate = openvino_stable_delegate;
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_external_test.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_external_test.cc
new file mode 100644
index 000000000000..bf7345afcd95
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_external_test.cc
@@ -0,0 +1,101 @@
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include "openvino_delegate.h"
+#include "tensorflow/lite/acceleration/configuration/configuration_generated.h"
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/c_api.h"
+#include "tensorflow/lite/core/kernels/builtin_op_kernels.h"
+#include "tensorflow/lite/delegates/utils/experimental/stable_delegate/delegate_loader.h"
+#include "tensorflow/lite/interpreter.h"
+#include "tensorflow/lite/interpreter_builder.h"
+#include "tensorflow/lite/kernels/kernel_util.h"
+#include "tensorflow/lite/kernels/register.h"
+
+namespace {
+
+using tflite::TFLiteSettings;
+using tflite::TFLiteSettingsBuilder;
+using tflite::delegates::utils::LoadDelegateFromSharedLibrary;
+
+class OpenVINODelegateExternalTest : public testing::Test {
+protected:
+    const TfLiteStableDelegate *stable_delegate_handle;
+    flatbuffers::Offset<TFLiteSettings> tflite_settings;
+    TfLiteInterpreter *interpreter;
+    TfLiteModel *model;
+};
+
+TEST_F(OpenVINODelegateExternalTest, LoadExternalDelegateLibrary) {
+    // Load stable opaque_delegate that implements the ADD operation
+    // from a shared libary file.
+    stable_delegate_handle = LoadDelegateFromSharedLibrary(
+        "bazel-bin/tensorflow/lite/delegates/openvino/"
+        "libtensorflowlite_openvino_stable_delegate.so");
+    ASSERT_NE(stable_delegate_handle, nullptr);
+    EXPECT_STREQ(stable_delegate_handle->delegate_abi_version, TFL_STABLE_DELEGATE_ABI_VERSION);
+    EXPECT_STREQ(stable_delegate_handle->delegate_name, kOpenVINOStableDelegateName);
+    EXPECT_STREQ(stable_delegate_handle->delegate_version, kOpenVINOStableDelegateVersion);
+    ASSERT_NE(stable_delegate_handle->delegate_plugin, nullptr);
+
+    // Build TFLiteSettings flatbuffer and pass into opaque_delegate plugin
+    // create method.
+    flatbuffers::FlatBufferBuilder flatbuffer_builder;
+    TFLiteSettingsBuilder tflite_settings_builder(flatbuffer_builder);
+    tflite_settings = tflite_settings_builder.Finish();
+    flatbuffer_builder.Finish(tflite_settings);
+    const TFLiteSettings *settings =
+        flatbuffers::GetRoot<TFLiteSettings>(flatbuffer_builder.GetBufferPointer());
+    TfLiteOpaqueDelegate *opaque_delegate =
+        stable_delegate_handle->delegate_plugin->create(settings);
+    ASSERT_NE(opaque_delegate, nullptr);
+
+    //
+    // Create the model and the interpreter
+    //
+    model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+    ASSERT_NE(model, nullptr);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    ASSERT_NE(options, nullptr);
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    interpreter = TfLiteInterpreterCreate(model, options);
+    ASSERT_NE(interpreter, nullptr);
+    // The options can be deleted immediately after interpreter creation.
+    TfLiteInterpreterOptionsDelete(options);
+
+    //
+    // Allocate the tensors and fill the input tensor.
+    //
+    ASSERT_EQ(TfLiteInterpreterAllocateTensors(interpreter), kTfLiteOk);
+    TfLiteTensor *input_tensor = TfLiteInterpreterGetInputTensor(interpreter, /*input_index=*/0);
+    ASSERT_NE(input_tensor, nullptr);
+    const float kTensorCellValue = 3.f;
+    int64_t n = tflite::NumElements(input_tensor);
+    std::vector<float> input(n, kTensorCellValue);
+    ASSERT_EQ(TfLiteTensorCopyFromBuffer(input_tensor, input.data(), input.size() * sizeof(float)),
+              kTfLiteOk);
+
+    //
+    // Run the interpreter and read the output tensor.
+    //
+    ASSERT_EQ(TfLiteInterpreterInvoke(interpreter), kTfLiteOk);
+
+    const TfLiteTensor *output_tensor = TfLiteInterpreterGetOutputTensor(interpreter, 0);
+    ASSERT_NE(output_tensor, nullptr);
+    std::vector<float> output(n, 0);
+    ASSERT_EQ(TfLiteTensorCopyToBuffer(output_tensor, output.data(), output.size() * sizeof(float)),
+              kTfLiteOk);
+
+    // The 'add.bin' model does the following operation ('t_output' denotes the
+    // single output tensor, and 't_input' denotes the single input tensor):
+    //
+    // t_output = t_input + t_input + t_input = t_input * 3
+    for (int i = 0; i < output.size(); ++i) {
+        EXPECT_EQ(output[i], kTensorCellValue * 3);
+    }
+
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    stable_delegate_handle->delegate_plugin->destroy(opaque_delegate);
+}
+
+}  // namespace
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_kernel.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_kernel.cc
new file mode 100644
index 000000000000..10e8666c2cf4
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_kernel.cc
@@ -0,0 +1,80 @@
+/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+#include "openvino_delegate_kernel.h"
+
+#include "openvino_delegate_core.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus OpenVINODelegateKernel::Init(TfLiteOpaqueContext *context,
+                                          const TfLiteOpaqueDelegateParams *params) {
+    TFLITE_LOG(INFO) << "Openvino delegate version 2.15.2v "
+                     << "\n";
+    // Should we do some NPU Init here.
+    TfLiteStatus init_status = ov_delegate_core_->OpenVINODelegateInit();
+    if (init_status != kTfLiteOk) {
+        return init_status;
+    }
+
+    TfLiteStatus set_status = ov_delegate_core_->CreateGraphfromTfLite(context, params);
+    if (set_status != kTfLiteOk) {
+        return set_status;
+    }
+    // TODO: get device string from flags
+
+    return kTfLiteOk;
+}
+
+TfLiteStatus OpenVINODelegateKernel::Prepare(TfLiteOpaqueContext *context, TfLiteOpaqueNode *node) {
+    TFLITE_LOG(INFO) << "inside Prepare \n";
+    return kTfLiteOk;
+}
+
+TfLiteStatus OpenVINODelegateKernel::Eval(TfLiteOpaqueContext *context, TfLiteOpaqueNode *node) {
+    std::vector<int> compute_inputs = ov_delegate_core_->getComputeInputs();
+    size_t i = 0;
+    for (int t : compute_inputs) {
+        ov::Tensor inputBlob = ov_delegate_core_->getInferRequest().get_input_tensor(i++);
+        uint8_t *dest = (uint8_t *)inputBlob.data<float>();
+
+        const TfLiteOpaqueTensor *opaque_input_tensor =
+            TfLiteOpaqueContextGetOpaqueTensor(context, t);
+        auto len = TfLiteOpaqueTensorByteSize(opaque_input_tensor);
+        void *srcPtr = TfLiteOpaqueTensorData(opaque_input_tensor);
+
+        float *src = (float *)srcPtr;
+        std::memcpy((uint8_t *)dest, (uint8_t *)srcPtr, len);
+    }
+    ov_delegate_core_->getInferRequest().start_async();
+    ov_delegate_core_->getInferRequest().wait_for(std::chrono::milliseconds(10000));
+    std::vector<int> outputs = ov_delegate_core_->getOutputs();
+    size_t o = 0;
+    for (int t : outputs) {
+        ov::Tensor outputBlob = ov_delegate_core_->getInferRequest().get_output_tensor(o);
+        const TfLiteOpaqueTensor *opaque_output_tensor =
+            TfLiteOpaqueContextGetOpaqueTensor(context, *(outputs.begin()));
+        void *srcPtr = TfLiteOpaqueTensorData(opaque_output_tensor);
+        uint8_t *dest = (uint8_t *)outputBlob.data<float>();
+        auto len = TfLiteOpaqueTensorByteSize(opaque_output_tensor);
+        std::memcpy((void *)srcPtr, (void *)dest, len);
+        o++;
+    }
+
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_kernel.h b/tensorflow/lite/delegates/openvino/openvino_delegate_kernel.h
new file mode 100644
index 000000000000..0f0af902eb84
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_kernel.h
@@ -0,0 +1,53 @@
+/* Copyright 2023 The TensorFlow Authors. All Rights Reserved.
+
+Licensed under the Apache License, Version 2.0 (the "License");
+you may not use this file except in compliance with the License.
+You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an "AS IS" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+==============================================================================*/
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_KERNEL_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_KERNEL_H_
+#include <map>
+#include <openvino/openvino.hpp>
+#include <openvino/opsets/opset3.hpp>
+#include <openvino/pass/manager.hpp>
+#include <openvino/pass/serialize.hpp>
+#include <openvino/runtime/core.hpp>
+#include <vector>
+
+#include "openvino_delegate_core.h"
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/common.h"
+#include "tensorflow/lite/delegates/utils/simple_opaque_delegate.h"
+#include "tensorflow/lite/tools/logging.h"
+
+namespace tflite {
+namespace openvinodelegate {
+class OpenVINODelegateKernel : public SimpleOpaqueDelegateKernelInterface {
+public:
+    explicit OpenVINODelegateKernel()
+        : ov_delegate_core_(std::make_unique<OpenVINODelegateCore>("")) {}
+
+    TfLiteStatus Init(TfLiteOpaqueContext *context,
+                      const TfLiteOpaqueDelegateParams *params) override;
+
+    TfLiteStatus Prepare(TfLiteOpaqueContext *context, TfLiteOpaqueNode *node) override;
+
+    TfLiteStatus Eval(TfLiteOpaqueContext *context, TfLiteOpaqueNode *node) override;
+    std::shared_ptr<ov::Node> ApplyActivation(std::shared_ptr<ov::Node> input,
+                                              TfLiteFusedActivation activation);
+
+private:
+    std::unique_ptr<OpenVINODelegateCore> ov_delegate_core_;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_DELEGATE_KERNEL_H_
diff --git a/tensorflow/lite/delegates/openvino/openvino_delegate_test.cc b/tensorflow/lite/delegates/openvino/openvino_delegate_test.cc
new file mode 100644
index 000000000000..b6794e682aef
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_delegate_test.cc
@@ -0,0 +1,206 @@
+#include "openvino_delegate.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/c_api.h"
+#include "tensorflow/lite/core/kernels/builtin_op_kernels.h"
+#include "tensorflow/lite/interpreter.h"
+#include "tensorflow/lite/interpreter_builder.h"
+#include "tensorflow/lite/kernels/kernel_util.h"
+#include "tensorflow/lite/kernels/register.h"
+
+std::function<void(TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node)> test_function_;
+namespace tflite {
+namespace openvinodelegate {
+
+class OpenVINODelegateTestPeer {
+public:
+    OpenVINODelegateTestPeer() {}
+
+    static bool CheckInputsType(const OpenVINODelegate &test_delegate, const int tensor_id,
+                                const TfLiteOpaqueContext *context, TfLiteType expected_type) {
+        return test_delegate.CheckInputsType(tensor_id, context, expected_type);
+    }
+    static bool CheckDataTypeSupported(const OpenVINODelegate &test_delegate,
+                                       const TfLiteOpaqueContext *context,
+                                       const TfLiteOpaqueNode *node,
+                                       std::vector<std::vector<TfLiteType>> supported_types) {
+        return test_delegate.CheckDataTypeSupported(context, node, supported_types);
+    }
+    static bool CheckDims(const OpenVINODelegate &test_delegate, const TfLiteOpaqueContext *context,
+                          const TfLiteOpaqueNode *node, std::vector<std::vector<int>> dims_size) {
+        return test_delegate.CheckDims(context, node, dims_size);
+    }
+};
+}  // namespace openvinodelegate
+}  // namespace tflite
+
+class OpenVINODelegateTest : public testing::Test {
+protected:
+    void setup_delegate(
+        std::function<void(TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node)>
+            test_function) {
+        TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+        test_function_ = test_function;
+        opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                             TfLiteOpaqueDelegate *opaque_delegate_,
+                                             void *data) -> TfLiteStatus {
+            // Test that an unnamed delegate kernel can be passed to the TF Lite
+            // runtime.
+
+            TfLiteIntArray *execution_plan;
+            TF_LITE_ENSURE_STATUS(
+                TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+            for (int i = 0; i < execution_plan->size; ++i) {
+                TfLiteOpaqueNode *node = nullptr;
+                TfLiteRegistrationExternal *registration = nullptr;
+                TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, i, &node, &registration);
+                bool is_supported = false;
+                test_function_(opaque_context, node);
+            }
+
+            TfLiteRegistrationExternal *registration_external =
+                TfLiteRegistrationExternalCreate(kTfLiteBuiltinDelegate,
+                                                 /*name*/ nullptr,
+                                                 /*version=*/1);
+            return TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(
+                opaque_context, registration_external, execution_plan, opaque_delegate_);
+        };
+        opaque_delegate_ = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+
+        tflite::ops::builtin::BuiltinOpResolver resolver;
+        tflite::InterpreterBuilder builder(*model, resolver);
+        builder.AddDelegate(opaque_delegate_);
+        EXPECT_EQ(kTfLiteOk, builder(&interpreter_));
+        ASSERT_NE(interpreter_, nullptr);
+    }
+
+    void SetUp() override {
+        model = tflite::FlatBufferModel::BuildFromFile("tensorflow/lite/testdata/add.bin");
+        ASSERT_NE(model, nullptr);
+    }
+
+    void TearDown() override { TfLiteOpaqueDelegateDelete(opaque_delegate_); }
+
+protected:
+    std::unique_ptr<tflite::Interpreter> interpreter_;
+    TfLiteOpaqueDelegate *opaque_delegate_ = nullptr;
+    TfLiteOpaqueContext *test_graph_context = nullptr;
+    std::unique_ptr<tflite::FlatBufferModel> model;
+    // static std::function<void (TfLiteOpaqueContext* opaque_context,
+    // TfLiteOpaqueNode* node)> test_function_;
+};
+
+TEST_F(OpenVINODelegateTest, CheckSupportedInputsTypeTest) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        tflite::openvinodelegate::OpenVINODelegateTestPeer test_peer;
+        EXPECT_EQ(true, test_peer.CheckDataTypeSupported(ov_del_test, opaque_context, node,
+                                                         {{kTfLiteFloat32}, {kTfLiteFloat32}}));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckUnsupportedInputsTypeTest) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        tflite::openvinodelegate::OpenVINODelegateTestPeer test_peer;
+        EXPECT_EQ(false, test_peer.CheckDataTypeSupported(ov_del_test, opaque_context, node,
+                                                          {{kTfLiteInt16}, {kTfLiteInt16}}));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckUnsupportedInputsTypeTest2) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        tflite::openvinodelegate::OpenVINODelegateTestPeer test_peer;
+        EXPECT_EQ(false, test_peer.CheckDataTypeSupported(ov_del_test, opaque_context, node,
+                                                          {{kTfLiteFloat32}, {kTfLiteInt16}}));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckSupportedInputsTypeTest2) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        tflite::openvinodelegate::OpenVINODelegateTestPeer test_peer;
+        EXPECT_EQ(true, test_peer.CheckDataTypeSupported(
+                            ov_del_test, opaque_context, node,
+                            {{kTfLiteFloat32}, {kTfLiteInt16, kTfLiteFloat32}}));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckInputsIsNodeSupportedByDelegate1) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        EXPECT_EQ(false, ov_del_test.IsNodeSupportedByDelegate(nullptr, node, opaque_context));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckInputsSupportedByDelegate2) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        EXPECT_EQ(false, ov_del_test.IsNodeSupportedByDelegate(nullptr, nullptr, opaque_context));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckInputsSupportedByDelegate3) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        EXPECT_EQ(false, ov_del_test.IsNodeSupportedByDelegate(nullptr, node, nullptr));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckNoSupportedTypes) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        tflite::openvinodelegate::OpenVINODelegateTestPeer test_peer;
+        EXPECT_EQ(false,
+                  test_peer.CheckDataTypeSupported(ov_del_test, opaque_context, node, {{}, {}}));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckDimsTest) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        tflite::openvinodelegate::OpenVINODelegateTestPeer test_peer;
+        EXPECT_EQ(false, test_peer.CheckDims(ov_del_test, opaque_context, node, {{4}, {4}, {4}}));
+    };
+    setup_delegate(test_func);
+}
+
+TEST_F(OpenVINODelegateTest, CheckDimsDynamicTest) {
+    auto test_func = [](TfLiteOpaqueContext *opaque_context, TfLiteOpaqueNode *node) -> void {
+        TfLiteOpenVINODelegateOptions options_del;
+        tflite::openvinodelegate::OpenVINODelegate ov_del_test =
+            tflite::openvinodelegate::OpenVINODelegate(&options_del);
+        tflite::openvinodelegate::OpenVINODelegateTestPeer test_peer;
+        EXPECT_EQ(false, test_peer.CheckDims(ov_del_test, opaque_context, node, {{0}, {4}}));
+    };
+    setup_delegate(test_func);
+}
\ No newline at end of file
diff --git a/tensorflow/lite/delegates/openvino/openvino_graph_builder.cc b/tensorflow/lite/delegates/openvino/openvino_graph_builder.cc
new file mode 100644
index 000000000000..d2178dc8d43d
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_graph_builder.cc
@@ -0,0 +1,146 @@
+#include "openvino_graph_builder.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus OpenVINOGraphBuilder::CreateNodeFromTfLiteOp(int node_id,
+                                                          TfLiteRegistrationExternal *registration,
+                                                          TfLiteOpaqueNode *node,
+                                                          TfLiteOpaqueContext *context) {
+    if (node_id < 0) return kTfLiteError;
+    if (registration == nullptr || node == nullptr || context == nullptr) return kTfLiteError;
+
+    std::shared_ptr<OperationsBase> operation_node;
+    TfLiteStatus node_status = CreateOpClass(node_id, registration, operation_node);
+    if (node_status != kTfLiteOk || !operation_node) return kTfLiteError;
+    operation_node->SetGraphData(context, node_manager_.get());
+
+    const int *inputs_data;
+    int num_inputs;
+    TfLiteStatus status = TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+    if (TfLiteRegistrationExternalGetBuiltInCode(registration) == kTfLiteBuiltinCustom &&
+        (strcmp(TfLiteRegistrationExternalGetCustomName(registration),
+                "Convolution2DTransposeBias") == 0)) {
+        const void *init_data;
+        int size;
+        if (TfLiteOpaqueNodeGetCustomInitialData(node, &init_data, &size) != kTfLiteOk) {
+            return kTfLiteDelegateError;
+        }
+        operation_node->UpdateNodeInfo((void *)inputs_data, num_inputs, (void *)init_data);
+        TfLiteTransposeConvParams transpose_conv_params = {kTfLitePaddingUnknown};
+    } else {
+        operation_node->UpdateNodeInfo((void *)inputs_data, num_inputs,
+                                       TfLiteOpaqueNodeGetBuiltinData(node));
+    }
+    if (operation_node->CreateNode() != kTfLiteOk)
+        return kTfLiteError;
+    else {
+        std::shared_ptr<ov::Node> result_node = operation_node->GetOpResultNode();
+        if (result_node == nullptr) return kTfLiteError;
+
+        const int *outputs;
+        int num_outputs;
+        TfLiteStatus tf_status = TfLiteOpaqueNodeOutputs(node, &outputs, &num_outputs);
+        node_manager_->setOutputAtOperandIndex(outputs[0], result_node);
+
+        return kTfLiteOk;
+    }
+}
+
+TfLiteStatus OpenVINOGraphBuilder::CreateOpClass(int operationIndex,
+                                                 TfLiteRegistrationExternal *registration,
+                                                 std::shared_ptr<OperationsBase> &op_base) {
+    if (operationIndex < 0) return kTfLiteError;
+    if (registration == nullptr) return kTfLiteError;
+
+    switch (TfLiteRegistrationExternalGetBuiltInCode(registration)) {
+        case kTfLiteBuiltinAdd: {
+            op_base = std::make_shared<Add>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinAveragePool2d: {
+            op_base = std::make_shared<AveragePool2D>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinConv2d: {
+            op_base = std::make_shared<Conv2D>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinConcatenation: {
+            op_base = std::make_shared<Concat>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinCustom: {
+            if (strcmp(TfLiteRegistrationExternalGetCustomName(registration),
+                       "Convolution2DTransposeBias") == 0) {
+                auto transpose_conv = std::make_shared<TransposeConv>(operationIndex);
+                transpose_conv->SetCustom(true);
+                op_base = transpose_conv;
+                return kTfLiteOk;
+            }
+            return kTfLiteError;
+        }
+        case kTfLiteBuiltinDepthwiseConv2d: {
+            op_base = std::make_shared<DepthwiseConv2D>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinDequantize: {
+            op_base = std::make_shared<Dequantize>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinMul: {
+            op_base = std::make_shared<Mul>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinResizeBilinear: {
+            op_base = std::make_shared<ResizeBilinear>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinRelu: {
+            op_base = std::make_shared<Relu>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinRelu6: {
+            op_base = std::make_shared<Relu6>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinLogistic: {
+            op_base = std::make_shared<Logistic>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinHardSwish: {
+            op_base = std::make_shared<HardSwish>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinSoftmax: {
+            op_base = std::make_shared<Softmax>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinTanh: {
+            op_base = std::make_shared<Tanh>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinReshape: {
+            op_base = std::make_shared<Reshape>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinMaxPool2d: {
+            op_base = std::make_shared<MaxPool2D>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinMean: {
+            op_base = std::make_shared<Mean>(operationIndex);
+            return kTfLiteOk;
+        }
+        case kTfLiteBuiltinTransposeConv: {
+            op_base = std::make_shared<TransposeConv>(operationIndex);
+            return kTfLiteOk;
+        }
+        default:
+            op_base = nullptr;
+            return kTfLiteError;
+    }
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/openvino_graph_builder.h b/tensorflow/lite/delegates/openvino/openvino_graph_builder.h
new file mode 100644
index 000000000000..f3b7f80b72e8
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_graph_builder.h
@@ -0,0 +1,215 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_GRAPH_BUILDER_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_GRAPH_BUILDER_H_
+#include <openvino/openvino.hpp>
+#include <openvino/opsets/opset3.hpp>
+#include <openvino/opsets/opset8.hpp>
+#include <vector>
+
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/builtin_op_data.h"
+#include "tensorflow/lite/c/common.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/add.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/average_pool_2d.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/concat.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/conv2d.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/depthwise_conv2d.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/dequantize.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/hardswish.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/logistic.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/maxpool2d.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/mean.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/mul.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/relu.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/relu6.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/reshape.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/resize_bilinear.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/softmax.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/tanh.h"
+#include "tensorflow/lite/delegates/openvino/operations/include/transpose_conv.h"
+
+#include "tensorflow/lite/delegates/openvino/operations/openvino_node_manager.h"
+#include "tensorflow/lite/tools/logging.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class OpenVINOGraphBuilder {
+public:
+    OpenVINOGraphBuilder(std::unique_ptr<NodeManager> node_manager) {
+        node_manager_ = std::move(node_manager);
+    }
+
+    TfLiteStatus convertNHWCtoNCHW(std::vector<int> node_dims, std::shared_ptr<ov::Node> input,
+                                   std::shared_ptr<ov::Node> &transposed_node) {
+        if (input == nullptr) return kTfLiteError;
+        if (node_dims.size() <= 0) return kTfLiteError;
+
+        ov::AxisVector order = {0, 3, 1, 2};
+        const auto order_node = std::make_shared<ov::opset8::Constant>(
+            ov::element::i32, ov::Shape{order.size()}, order);
+
+        if (node_dims.size() < 4 && node_dims.size() > 0) {
+            auto size = node_dims.size();
+            for (int i = 0; i < 4 - size; i++) {
+                node_dims.insert(node_dims.begin(), 1);
+            }
+            auto new_size =
+                std::make_shared<ov::opset8::Constant>(ov::element::i32, ov::Shape{4}, node_dims);
+            input = std::make_shared<ov::opset8::Reshape>(input, new_size, false);
+        }
+
+        if (node_dims.size() >= 5) {
+            TFLITE_LOG(ERROR) << "5D or greater than 5D tensors are not supported\n";
+            return kTfLiteError;
+        }
+        transposed_node = std::make_shared<ov::opset3::Transpose>(input, order_node);
+
+        return kTfLiteOk;
+    }
+
+    TfLiteStatus AddInputParams(const TfLiteOpaqueTensor *t, const int index) {
+        if (t == nullptr) return kTfLiteError;
+        if (index < 0) return kTfLiteError;
+
+        int32_t num_dims = TfLiteOpaqueTensorNumDims(t);
+        std::vector<int> dims(num_dims);
+        for (int i = 0; i < num_dims; i++) {
+            dims[i] = TfLiteOpaqueTensorDim(t, i);
+        }
+
+        if (dims.size() <= 0) return kTfLiteError;
+
+        auto input = std::make_shared<ov::opset3::Parameter>(ov::element::f32,
+                                                             ov::Shape(dims.begin(), dims.end()));
+        if (input == NULL) {
+            return kTfLiteError;
+        }
+        input_params_.push_back(input);
+
+        std::shared_ptr<ov::Node> interim;
+        if (convertNHWCtoNCHW(dims, input, interim) != kTfLiteOk) return kTfLiteError;
+        if (interim == nullptr) return kTfLiteError;
+        node_manager_->setOutputAtOperandIndex(index, interim);
+        node_manager_->insertIndexParameters(index);
+
+        return kTfLiteOk;
+    }
+
+    TfLiteStatus CreateConstNode(const TfLiteOpaqueContext *context, const int index) {
+        if (context == nullptr) return kTfLiteError;
+        const TfLiteOpaqueTensor *t = TfLiteOpaqueContextGetOpaqueTensor(context, index);
+        int32_t num_dims;
+        ov::element::Type ov_element_type;
+        num_dims = TfLiteOpaqueTensorNumDims(t);
+        std::vector<int> dims(num_dims);
+        for (int i = 0; i < num_dims; i++) {
+            dims[i] = TfLiteOpaqueTensorDim(t, i);
+        }
+
+        if (dims.size() <= 0) return kTfLiteError;
+
+        const void *data = TfLiteOpaqueTensorData(t);
+        if (data == NULL) {
+            return kTfLiteError;
+        }
+
+        TfLiteType tensor_type = TfLiteOpaqueTensorType(t);
+        switch (tensor_type) {
+            case kTfLiteFloat32:
+                ov_element_type = ov::element::f32;
+                break;
+            case kTfLiteInt32:
+                ov_element_type = ov::element::i32;
+                break;
+            case kTfLiteUInt8:
+                ov_element_type = ov::element::u8;
+                break;
+            case kTfLiteInt64:
+                ov_element_type = ov::element::i64;
+                break;
+            case kTfLiteBool:
+                ov_element_type = ov::element::boolean;
+                break;
+            case kTfLiteInt16:
+                ov_element_type = ov::element::i16;
+                break;
+            case kTfLiteInt8:
+                ov_element_type = ov::element::i8;
+                break;
+            case kTfLiteFloat16:
+                ov_element_type = ov::element::f16;
+                break;
+            case kTfLiteFloat64:
+                ov_element_type = ov::element::f64;
+                break;
+            case kTfLiteUInt64:
+                ov_element_type = ov::element::u64;
+                break;
+            case kTfLiteUInt32:
+                ov_element_type = ov::element::u32;
+                break;
+            case kTfLiteUInt16:
+                ov_element_type = ov::element::u16;
+                break;
+            case kTfLiteInt4:
+                ov_element_type = ov::element::i4;
+                break;
+            default:
+                TFLITE_LOG(ERROR) << "Element type " << tensor_type << " not supported\n";
+                return kTfLiteError;
+        }
+
+        auto const_node = std::make_shared<ov::opset8::Constant>(
+            ov_element_type, ov::Shape(dims.begin(), dims.end()), data);
+        if (const_node == NULL) {
+            TFLITE_LOG(INFO) << "Error in creating const node\n";
+            return kTfLiteError;
+        }
+        node_manager_->setOutputAtOperandIndex(index, const_node);
+
+        return kTfLiteOk;
+    }
+
+    TfLiteStatus UpdateResultNodes(const TfLiteOpaqueContext *context, std::vector<int> outputs) {
+        if (context == nullptr) return kTfLiteError;
+        if (outputs.size() < 1) return kTfLiteError;
+
+        for (auto o : outputs) {
+            auto out_node = node_manager_->getInterimNodeOutput(o);
+            auto dims = out_node->get_shape();
+            if (dims.size() == 4) {
+                ov::AxisVector order;
+                order = {0, 2, 3, 1};
+                const auto order_node = std::make_shared<ov::opset8::Constant>(
+                    ov::element::i64, ov::Shape{order.size()}, order);
+                out_node = std::make_shared<ov::opset3::Transpose>(out_node, order_node);
+                if (out_node == NULL) {
+                    TFLITE_LOG(INFO) << "Error in creating transpose for result node\n";
+                    return kTfLiteError;
+                }
+            }
+            result_nodes_.push_back(out_node);
+        }
+
+        return kTfLiteOk;
+    }
+
+    std::vector<std::shared_ptr<ov::Node>> getResultNodes() { return result_nodes_; }
+
+    std::vector<std::shared_ptr<ov::opset3::Parameter>> getInputParams() { return input_params_; }
+
+    size_t getNodeManagerSize() const { return node_manager_->getNodeCount(); }
+
+    TfLiteStatus CreateNodeFromTfLiteOp(int node_id, TfLiteRegistrationExternal *registration,
+                                        TfLiteOpaqueNode *node, TfLiteOpaqueContext *context);
+    TfLiteStatus CreateOpClass(int operationIndex, TfLiteRegistrationExternal *registration,
+                               std::shared_ptr<OperationsBase> &op_base);
+
+private:
+    std::shared_ptr<NodeManager> node_manager_;
+    std::vector<std::shared_ptr<ov::opset3::Parameter>> input_params_;
+    std::vector<std::shared_ptr<ov::Node>> result_nodes_;
+};
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_GRAPH_BUILDER_H_
diff --git a/tensorflow/lite/delegates/openvino/openvino_graph_builder_test.cc b/tensorflow/lite/delegates/openvino/openvino_graph_builder_test.cc
new file mode 100644
index 000000000000..4841b5e6f18f
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/openvino_graph_builder_test.cc
@@ -0,0 +1,1114 @@
+#include "openvino_graph_builder.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <openvino/pass/manager.hpp>
+#include <openvino/pass/serialize.hpp>
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/c_api.h"
+#include "tensorflow/lite/core/kernels/builtin_op_kernels.h"
+#include "tensorflow/lite/interpreter.h"
+#include "tensorflow/lite/interpreter_builder.h"
+#include "tensorflow/lite/kernels/kernel_util.h"
+#include "tensorflow/lite/kernels/register.h"
+
+std::function<void(TfLiteOpaqueTensor *opaque_tensor, const int index)> test_function_;
+
+class OpenVINOGraphBuilderTest : public testing::Test {
+protected:
+    void SetUp() override {
+        model = tflite::FlatBufferModel::BuildFromFile("tensorflow/lite/testdata/add.bin");
+        ASSERT_NE(model, nullptr);
+    }
+    void TearDown() override { TfLiteOpaqueDelegateDelete(opaque_delegate_); }
+
+protected:
+    std::unique_ptr<tflite::Interpreter> interpreter_;
+    TfLiteOpaqueDelegate *opaque_delegate_ = nullptr;
+    TfLiteOpaqueContext *test_graph_context = nullptr;
+    std::unique_ptr<tflite::FlatBufferModel> model;
+};
+
+TfLiteOpaqueTensor *create_opaque_tensor(TfLiteTensor *t) { return (TfLiteOpaqueTensor *)t; }
+
+TEST_F(OpenVINOGraphBuilderTest, AddInputParamsTest_VALID) {
+    TfLiteTensor t;
+    const int kNumElements = 32;
+    const int kBytes = sizeof(float) * kNumElements;
+    memset(&t, 0, sizeof(TfLiteTensor));
+    t.bytes = kBytes;
+    t.data_is_stale = true;
+    t.allocation_type = kTfLiteDynamic;
+    t.type = kTfLiteFloat32;
+    t.dims = TfLiteIntArrayCreate(2);
+    t.dims->data[0] = 4;
+    t.dims->data[1] = 8;
+    t.dims_signature = TfLiteIntArrayCopy(t.dims);
+    t.buffer_handle = 5;
+
+    TfLiteOpaqueTensor *opaque_t = create_opaque_tensor(&t);
+
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    EXPECT_EQ(kTfLiteOk, openvino_graph_builder_test->AddInputParams(opaque_t, 0));
+    EXPECT_EQ(true, openvino_graph_builder_test->getNodeManagerSize() == 1);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, AddInputParamsTest_InvalidTensor) {
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->AddInputParams(nullptr, 0));
+    EXPECT_EQ(false, openvino_graph_builder_test->getNodeManagerSize() == 1);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, AddInputParamsTest_InvalidIndex) {
+    TfLiteTensor t;
+    const int kNumElements = 32;
+    const int kBytes = sizeof(float) * kNumElements;
+    memset(&t, 0, sizeof(TfLiteTensor));
+    t.bytes = kBytes;
+    // t.delegate = &delegate;
+    t.data_is_stale = true;
+    t.allocation_type = kTfLiteDynamic;
+    t.type = kTfLiteFloat32;
+    t.dims = TfLiteIntArrayCreate(2);
+    t.dims->data[0] = 4;
+    t.dims->data[1] = 8;
+    t.dims_signature = TfLiteIntArrayCopy(t.dims);
+    t.buffer_handle = 5;
+
+    TfLiteOpaqueTensor *opaque_t = create_opaque_tensor(&t);
+
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->AddInputParams(opaque_t, -1));
+    EXPECT_EQ(false, openvino_graph_builder_test->getNodeManagerSize() == 1);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, convertNHWCtoNCHW_Valid) {
+    std::vector<int> dims = {1, 2, 3, 4};
+    auto input = std::make_shared<ov::opset3::Parameter>(ov::element::Type_t::f32,
+                                                         ov::Shape(dims.begin(), dims.end()));
+
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    std::shared_ptr<ov::Node> interim;
+    EXPECT_EQ(kTfLiteOk, openvino_graph_builder_test->convertNHWCtoNCHW(dims, input, interim));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, convertNHWCtoNCHW_InvalidNode) {
+    std::vector<int> dims = {1, 2, 3, 4};
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    std::shared_ptr<ov::Node> interim;
+    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->convertNHWCtoNCHW(dims, nullptr, interim));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, convertNHWCtoNCHW_InvalidDims) {
+    std::vector<int> dims = {1, 2, 3, 4, 5, 6};
+    auto input = std::make_shared<ov::opset3::Parameter>(ov::element::Type_t::f32,
+                                                         ov::Shape(dims.begin(), dims.end()));
+
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    std::shared_ptr<ov::Node> interim;
+    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->convertNHWCtoNCHW(dims, input, interim));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateConstNode_Invalid) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        for (int i = 0; i < execution_plan->size; ++i) {
+            TfLiteOpaqueNode *node = nullptr;
+            TfLiteRegistrationExternal *registration = nullptr;
+            TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, i, &node, &registration);
+            bool is_supported = false;
+            const int *inputs_data;
+            int num_inputs;
+            TfLiteStatus tf_status = TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+            const int t = inputs_data[0];
+            auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+            auto openvino_graph_builder_test =
+                std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                    std::make_unique<NodeManager>());
+
+            EXPECT_EQ(kTfLiteError,
+                      openvino_graph_builder_test->CreateConstNode(opaque_context, 0));
+        }
+
+        TfLiteRegistrationExternal *registration_external =
+            TfLiteRegistrationExternalCreate(kTfLiteBuiltinDelegate,
+                                             /*name*/ nullptr,
+                                             /*version=*/1);
+        return TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(
+            opaque_context, registration_external, execution_plan, opaque_delegate_);
+    };
+
+    opaque_delegate_ = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+
+    tflite::ops::builtin::BuiltinOpResolver resolver;
+    tflite::InterpreterBuilder builder(*model, resolver);
+    builder.AddDelegate(opaque_delegate_);
+
+    EXPECT_EQ(kTfLiteOk, builder(&interpreter_));
+    EXPECT_TRUE(delegate_prepared);
+    ASSERT_NE(interpreter_, nullptr);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateConstNode_InvalidContext) {
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->CreateConstNode(nullptr, 0));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateConstNode_InvalidIndex) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        for (int i = 0; i < execution_plan->size; ++i) {
+            TfLiteOpaqueNode *node = nullptr;
+            TfLiteRegistrationExternal *registration = nullptr;
+            TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, i, &node, &registration);
+            bool is_supported = false;
+            const int *inputs_data;
+            int num_inputs;
+            TfLiteStatus tf_status = TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+            const int t = inputs_data[0];
+            auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+            auto openvino_graph_builder_test =
+                std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                    std::make_unique<NodeManager>());
+
+            EXPECT_EQ(kTfLiteError,
+                      openvino_graph_builder_test->CreateConstNode(opaque_context, 1));
+        }
+
+        TfLiteRegistrationExternal *registration_external =
+            TfLiteRegistrationExternalCreate(kTfLiteBuiltinDelegate,
+                                             /*name*/ nullptr,
+                                             /*version=*/1);
+        return TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(
+            opaque_context, registration_external, execution_plan, opaque_delegate_);
+    };
+    opaque_delegate_ = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+
+    tflite::ops::builtin::BuiltinOpResolver resolver;
+    tflite::InterpreterBuilder builder(*model, resolver);
+    builder.AddDelegate(opaque_delegate_);
+
+    EXPECT_EQ(kTfLiteOk, builder(&interpreter_));
+    EXPECT_TRUE(delegate_prepared);
+    ASSERT_NE(interpreter_, nullptr);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, UpdateResultNodes_Valid) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext *opaque_context, const char *buffer, size_t length) -> void * {
+                auto openvino_graph_builder_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                        std::make_unique<NodeManager>());
+                std::vector<int> compute_inputs_ = {};
+                std::vector<int> outputs_ = {};
+                const TfLiteOpaqueDelegateParams *params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams *>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                for (int o = 0; o < params->output_tensors->size; o++) {
+                    const int output_tensor_idx = params->output_tensors->data[o];
+                    outputs_.push_back(output_tensor_idx);
+                }
+                for (int i = 0; i < params->nodes_to_replace->size; ++i) {
+                    const int delegate_node_id = params->nodes_to_replace->data[i];
+                    TfLiteOpaqueNode *node = nullptr;
+                    TfLiteRegistrationExternal *registration = nullptr;
+                    TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, delegate_node_id,
+                                                              &node, &registration);
+                    int inputs_size = TfLiteOpaqueNodeNumberOfInputs(node);
+                    for (int k = 0; k < inputs_size; k++) {
+                        const int *inputs_data;
+                        int num_inputs;
+                        TfLiteStatus tf_status =
+                            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+                        const int t = inputs_data[k];
+                        const void *data = nullptr;
+                        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+                        auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+                        if (allocation_type == kTfLiteMmapRo) {
+                            data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                            if (openvino_graph_builder_test->CreateConstNode(opaque_context, t) !=
+                                kTfLiteOk)
+                                exit(0);
+                        }
+                        if (inputs.count(t) != 0) {
+                            if (data == nullptr) {
+                                if (openvino_graph_builder_test->AddInputParams(opaque_tensor, t) !=
+                                    kTfLiteOk)
+                                    exit(0);
+                                compute_inputs_.push_back(t);
+                            }
+                        }
+                    }
+                    if (openvino_graph_builder_test->CreateNodeFromTfLiteOp(
+                            delegate_node_id, registration, node, opaque_context) != kTfLiteOk)
+                        exit(0);
+                }
+
+                EXPECT_EQ(kTfLiteOk,
+                          openvino_graph_builder_test->UpdateResultNodes(opaque_context, outputs_));
+                std::shared_ptr<ov::Model> model =
+                    std::make_shared<ov::Model>(openvino_graph_builder_test->getResultNodes(),
+                                                openvino_graph_builder_test->getInputParams());
+                ov::Core openvino_delegate_core_;
+                ov::CompiledModel compiled_model_;
+                std::string deviceStr = "CPU";
+                ov::InferRequest infer_request_;
+                if (model) {
+                    compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+                }
+
+                infer_request_ = compiled_model_.create_infer_request();
+                return &compiled_model_;
+            });
+
+        TfLiteRegistrationExternalSetInvoke(
+            reg_ex,
+            [](TfLiteOpaqueContext *context, TfLiteOpaqueNode *opaque_node) -> TfLiteStatus {
+                return kTfLiteOk;
+            });
+
+        TfLiteRegistrationExternalSetFree(reg_ex, [](TfLiteOpaqueContext *context, void *data) {});
+
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(opaque_context, reg_ex,
+                                                                 execution_plan, opaque_delegate_);
+        return kTfLiteOk;
+    };
+
+    TfLiteModel *model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+
+    TfLiteOpaqueDelegate *opaque_delegate = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
+
+    EXPECT_TRUE(delegate_prepared);
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    TfLiteOpaqueDelegateDelete(opaque_delegate);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, UpdateResultNodes_InvalidContext) {
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->UpdateResultNodes(nullptr, {0}));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, UpdateResultNodes_InvalidIndex) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext *opaque_context, const char *buffer, size_t length) -> void * {
+                auto openvino_graph_builder_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                        std::make_unique<NodeManager>());
+                std::vector<int> compute_inputs_ = {};
+                std::vector<int> outputs_ = {};
+                const TfLiteOpaqueDelegateParams *params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams *>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                for (int o = 0; o < params->output_tensors->size; o++) {
+                    const int output_tensor_idx = params->output_tensors->data[o];
+                    outputs_.push_back(output_tensor_idx);
+                }
+                for (int i = 0; i < params->nodes_to_replace->size; ++i) {
+                    const int delegate_node_id = params->nodes_to_replace->data[i];
+                    TfLiteOpaqueNode *node = nullptr;
+                    TfLiteRegistrationExternal *registration = nullptr;
+                    TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, delegate_node_id,
+                                                              &node, &registration);
+                    int inputs_size = TfLiteOpaqueNodeNumberOfInputs(node);
+                    for (int k = 0; k < inputs_size; k++) {
+                        const int *inputs_data;
+                        int num_inputs;
+                        TfLiteStatus tf_status =
+                            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+                        const int t = inputs_data[k];
+                        const void *data = nullptr;
+                        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+                        auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+                        if (allocation_type == kTfLiteMmapRo) {
+                            data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                            if (openvino_graph_builder_test->CreateConstNode(opaque_context, t) !=
+                                kTfLiteOk)
+                                exit(0);
+                        }
+                        if (inputs.count(t) != 0) {
+                            if (data == nullptr) {
+                                static int count = 0;
+                                if (count == 0) {
+                                    if (openvino_graph_builder_test->AddInputParams(opaque_tensor,
+                                                                                    t) != kTfLiteOk)
+                                        exit(0);
+                                    compute_inputs_.push_back(t);
+                                    count++;
+                                }
+                            }
+                        }
+                    }
+                    if (openvino_graph_builder_test->CreateNodeFromTfLiteOp(
+                            delegate_node_id, registration, node, opaque_context) != kTfLiteOk)
+                        exit(0);
+                }
+
+                EXPECT_EQ(kTfLiteError,
+                          openvino_graph_builder_test->UpdateResultNodes(opaque_context, {}));
+                std::shared_ptr<ov::Model> model =
+                    std::make_shared<ov::Model>(openvino_graph_builder_test->getResultNodes(),
+                                                openvino_graph_builder_test->getInputParams());
+                ov::Core openvino_delegate_core_;
+                ov::CompiledModel compiled_model_;
+                std::string deviceStr = "CPU";
+                ov::InferRequest infer_request_;
+                if (model) {
+                    compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+                    ov::pass::Manager manager;
+                    manager.register_pass<ov::pass::Serialize>("model.xml", "model.bin");
+                    manager.run_passes(model);
+                }
+
+                infer_request_ = compiled_model_.create_infer_request();
+                return &compiled_model_;
+            });
+
+        TfLiteRegistrationExternalSetInvoke(
+            reg_ex,
+            [](TfLiteOpaqueContext *context, TfLiteOpaqueNode *opaque_node) -> TfLiteStatus {
+                return kTfLiteOk;
+            });
+
+        TfLiteRegistrationExternalSetFree(reg_ex, [](TfLiteOpaqueContext *context, void *data) {});
+
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(opaque_context, reg_ex,
+                                                                 execution_plan, opaque_delegate_);
+        return kTfLiteOk;
+    };
+
+    TfLiteModel *model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+
+    TfLiteOpaqueDelegate *opaque_delegate = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
+
+    EXPECT_TRUE(delegate_prepared);
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    TfLiteOpaqueDelegateDelete(opaque_delegate);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateOpClass_ValidIndex) {
+    struct TfLiteRegistrationExternal registration;
+    registration.version = 1;
+    registration.builtin_code = kTfLiteBuiltinAdd;
+    registration.node_index = 1;
+    int operationIndex = 1;
+
+    std::shared_ptr<tflite::openvinodelegate::OperationsBase> op_base;
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    EXPECT_EQ(kTfLiteOk,
+              openvino_graph_builder_test->CreateOpClass(operationIndex, &registration, op_base));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateOpClass_InvalidIndex) {
+    struct TfLiteRegistrationExternal registration;
+    registration.version = 1;
+    registration.builtin_code = kTfLiteBuiltinAdd;
+    registration.node_index = -1;
+    int operationIndex = -1;
+
+    std::shared_ptr<tflite::openvinodelegate::OperationsBase> op_base;
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    EXPECT_EQ(kTfLiteError,
+              openvino_graph_builder_test->CreateOpClass(operationIndex, &registration, op_base));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateOpClass_InvalidRegistration) {
+    int operationIndex = 0;
+
+    std::shared_ptr<tflite::openvinodelegate::OperationsBase> op_base;
+    auto openvino_graph_builder_test =
+        std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+            std::make_unique<NodeManager>());
+
+    EXPECT_EQ(kTfLiteError,
+              openvino_graph_builder_test->CreateOpClass(operationIndex, nullptr, op_base));
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateNodeFromTfLiteOp_Valid) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext *opaque_context, const char *buffer, size_t length) -> void * {
+                auto openvino_graph_builder_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                        std::make_unique<NodeManager>());
+                std::vector<int> compute_inputs_ = {};
+                std::vector<int> outputs_ = {};
+                const TfLiteOpaqueDelegateParams *params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams *>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                for (int o = 0; o < params->output_tensors->size; o++) {
+                    const int output_tensor_idx = params->output_tensors->data[o];
+                    outputs_.push_back(output_tensor_idx);
+                }
+                for (int i = 0; i < params->nodes_to_replace->size; ++i) {
+                    const int delegate_node_id = params->nodes_to_replace->data[i];
+                    TfLiteOpaqueNode *node = nullptr;
+                    TfLiteRegistrationExternal *registration = nullptr;
+                    TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, delegate_node_id,
+                                                              &node, &registration);
+                    int inputs_size = TfLiteOpaqueNodeNumberOfInputs(node);
+                    for (int k = 0; k < inputs_size; k++) {
+                        const int *inputs_data;
+                        int num_inputs;
+                        TfLiteStatus tf_status =
+                            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+                        const int t = inputs_data[k];
+                        const void *data = nullptr;
+                        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+                        auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+                        if (allocation_type == kTfLiteMmapRo) {
+                            data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                            if (openvino_graph_builder_test->CreateConstNode(opaque_context, t) !=
+                                kTfLiteOk)
+                                exit(0);
+                        }
+                        if (inputs.count(t) != 0) {
+                            if (data == nullptr) {
+                                static int count = 0;
+                                if (count == 0) {
+                                    if (openvino_graph_builder_test->AddInputParams(opaque_tensor,
+                                                                                    t) != kTfLiteOk)
+                                        exit(0);
+                                    compute_inputs_.push_back(t);
+                                    count++;
+                                }
+                            }
+                        }
+                    }
+                    EXPECT_EQ(kTfLiteOk, openvino_graph_builder_test->CreateNodeFromTfLiteOp(
+                                             delegate_node_id, registration, node, opaque_context));
+                }
+
+                openvino_graph_builder_test->UpdateResultNodes(opaque_context, {});
+                std::shared_ptr<ov::Model> model =
+                    std::make_shared<ov::Model>(openvino_graph_builder_test->getResultNodes(),
+                                                openvino_graph_builder_test->getInputParams());
+                ov::Core openvino_delegate_core_;
+                ov::CompiledModel compiled_model_;
+                std::string deviceStr = "CPU";
+                ov::InferRequest infer_request_;
+                if (model) {
+                    compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+                    ov::pass::Manager manager;
+                    manager.register_pass<ov::pass::Serialize>("model.xml", "model.bin");
+                    manager.run_passes(model);
+                }
+
+                infer_request_ = compiled_model_.create_infer_request();
+                return &compiled_model_;
+            });
+
+        TfLiteRegistrationExternalSetInvoke(
+            reg_ex,
+            [](TfLiteOpaqueContext *context, TfLiteOpaqueNode *opaque_node) -> TfLiteStatus {
+                return kTfLiteOk;
+            });
+
+        TfLiteRegistrationExternalSetFree(reg_ex, [](TfLiteOpaqueContext *context, void *data) {});
+
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(opaque_context, reg_ex,
+                                                                 execution_plan, opaque_delegate_);
+        return kTfLiteOk;
+    };
+
+    TfLiteModel *model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+
+    TfLiteOpaqueDelegate *opaque_delegate = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
+
+    EXPECT_TRUE(delegate_prepared);
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    TfLiteOpaqueDelegateDelete(opaque_delegate);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateNodeFromTfLiteOp_InvalidNodeId) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext *opaque_context, const char *buffer, size_t length) -> void * {
+                auto openvino_graph_builder_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                        std::make_unique<NodeManager>());
+                std::vector<int> compute_inputs_ = {};
+                std::vector<int> outputs_ = {};
+                const TfLiteOpaqueDelegateParams *params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams *>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                for (int o = 0; o < params->output_tensors->size; o++) {
+                    const int output_tensor_idx = params->output_tensors->data[o];
+                    outputs_.push_back(output_tensor_idx);
+                }
+                for (int i = 0; i < params->nodes_to_replace->size; ++i) {
+                    const int delegate_node_id = params->nodes_to_replace->data[i];
+                    TfLiteOpaqueNode *node = nullptr;
+                    TfLiteRegistrationExternal *registration = nullptr;
+                    TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, delegate_node_id,
+                                                              &node, &registration);
+                    int inputs_size = TfLiteOpaqueNodeNumberOfInputs(node);
+                    for (int k = 0; k < inputs_size; k++) {
+                        const int *inputs_data;
+                        int num_inputs;
+                        TfLiteStatus tf_status =
+                            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+                        const int t = inputs_data[k];
+                        const void *data = nullptr;
+                        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+                        auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+                        if (allocation_type == kTfLiteMmapRo) {
+                            data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                            if (openvino_graph_builder_test->CreateConstNode(opaque_context, t) !=
+                                kTfLiteOk)
+                                exit(0);
+                        }
+                        if (inputs.count(t) != 0) {
+                            if (data == nullptr) {
+                                static int count = 0;
+                                if (count == 0) {
+                                    if (openvino_graph_builder_test->AddInputParams(opaque_tensor,
+                                                                                    t) != kTfLiteOk)
+                                        exit(0);
+                                    compute_inputs_.push_back(t);
+                                    count++;
+                                }
+                            }
+                        }
+                    }
+                    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->CreateNodeFromTfLiteOp(
+                                                -1, registration, node, opaque_context));
+                }
+
+                openvino_graph_builder_test->UpdateResultNodes(opaque_context, {});
+                std::shared_ptr<ov::Model> model =
+                    std::make_shared<ov::Model>(openvino_graph_builder_test->getResultNodes(),
+                                                openvino_graph_builder_test->getInputParams());
+                ov::Core openvino_delegate_core_;
+                ov::CompiledModel compiled_model_;
+                std::string deviceStr = "CPU";
+                ov::InferRequest infer_request_;
+                if (model) {
+                    compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+                    ov::pass::Manager manager;
+                    manager.register_pass<ov::pass::Serialize>("model.xml", "model.bin");
+                    manager.run_passes(model);
+                }
+
+                infer_request_ = compiled_model_.create_infer_request();
+                return &compiled_model_;
+            });
+
+        TfLiteRegistrationExternalSetInvoke(
+            reg_ex,
+            [](TfLiteOpaqueContext *context, TfLiteOpaqueNode *opaque_node) -> TfLiteStatus {
+                return kTfLiteOk;
+            });
+
+        TfLiteRegistrationExternalSetFree(reg_ex, [](TfLiteOpaqueContext *context, void *data) {});
+
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(opaque_context, reg_ex,
+                                                                 execution_plan, opaque_delegate_);
+        return kTfLiteOk;
+    };
+
+    TfLiteModel *model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+
+    TfLiteOpaqueDelegate *opaque_delegate = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
+
+    EXPECT_TRUE(delegate_prepared);
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    TfLiteOpaqueDelegateDelete(opaque_delegate);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateNodeFromTfLiteOp_InvalidRegistration) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext *opaque_context, const char *buffer, size_t length) -> void * {
+                auto openvino_graph_builder_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                        std::make_unique<NodeManager>());
+                std::vector<int> compute_inputs_ = {};
+                std::vector<int> outputs_ = {};
+                const TfLiteOpaqueDelegateParams *params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams *>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                for (int o = 0; o < params->output_tensors->size; o++) {
+                    const int output_tensor_idx = params->output_tensors->data[o];
+                    outputs_.push_back(output_tensor_idx);
+                }
+                for (int i = 0; i < params->nodes_to_replace->size; ++i) {
+                    const int delegate_node_id = params->nodes_to_replace->data[i];
+                    TfLiteOpaqueNode *node = nullptr;
+                    TfLiteRegistrationExternal *registration = nullptr;
+                    TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, delegate_node_id,
+                                                              &node, &registration);
+                    int inputs_size = TfLiteOpaqueNodeNumberOfInputs(node);
+                    for (int k = 0; k < inputs_size; k++) {
+                        const int *inputs_data;
+                        int num_inputs;
+                        TfLiteStatus tf_status =
+                            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+                        const int t = inputs_data[k];
+                        const void *data = nullptr;
+                        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+                        auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+                        if (allocation_type == kTfLiteMmapRo) {
+                            data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                            if (openvino_graph_builder_test->CreateConstNode(opaque_context, t) !=
+                                kTfLiteOk)
+                                exit(0);
+                        }
+                        if (inputs.count(t) != 0) {
+                            if (data == nullptr) {
+                                static int count = 0;
+                                if (count == 0) {
+                                    if (openvino_graph_builder_test->AddInputParams(opaque_tensor,
+                                                                                    t) != kTfLiteOk)
+                                        exit(0);
+                                    compute_inputs_.push_back(t);
+                                    count++;
+                                }
+                            }
+                        }
+                    }
+                    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->CreateNodeFromTfLiteOp(
+                                                delegate_node_id, nullptr, node, opaque_context));
+                }
+
+                openvino_graph_builder_test->UpdateResultNodes(opaque_context, {});
+                std::shared_ptr<ov::Model> model =
+                    std::make_shared<ov::Model>(openvino_graph_builder_test->getResultNodes(),
+                                                openvino_graph_builder_test->getInputParams());
+                ov::Core openvino_delegate_core_;
+                ov::CompiledModel compiled_model_;
+                std::string deviceStr = "CPU";
+                ov::InferRequest infer_request_;
+                if (model) {
+                    compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+                    ov::pass::Manager manager;
+                    manager.register_pass<ov::pass::Serialize>("model.xml", "model.bin");
+                    manager.run_passes(model);
+                }
+
+                infer_request_ = compiled_model_.create_infer_request();
+                return &compiled_model_;
+            });
+
+        TfLiteRegistrationExternalSetInvoke(
+            reg_ex,
+            [](TfLiteOpaqueContext *context, TfLiteOpaqueNode *opaque_node) -> TfLiteStatus {
+                return kTfLiteOk;
+            });
+
+        TfLiteRegistrationExternalSetFree(reg_ex, [](TfLiteOpaqueContext *context, void *data) {});
+
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(opaque_context, reg_ex,
+                                                                 execution_plan, opaque_delegate_);
+        return kTfLiteOk;
+    };
+
+    TfLiteModel *model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+
+    TfLiteOpaqueDelegate *opaque_delegate = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
+
+    EXPECT_TRUE(delegate_prepared);
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    TfLiteOpaqueDelegateDelete(opaque_delegate);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateNodeFromTfLiteOp_InvalidNode) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext *opaque_context, const char *buffer, size_t length) -> void * {
+                auto openvino_graph_builder_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                        std::make_unique<NodeManager>());
+                std::vector<int> compute_inputs_ = {};
+                std::vector<int> outputs_ = {};
+                const TfLiteOpaqueDelegateParams *params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams *>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                for (int o = 0; o < params->output_tensors->size; o++) {
+                    const int output_tensor_idx = params->output_tensors->data[o];
+                    outputs_.push_back(output_tensor_idx);
+                }
+                for (int i = 0; i < params->nodes_to_replace->size; ++i) {
+                    const int delegate_node_id = params->nodes_to_replace->data[i];
+                    TfLiteOpaqueNode *node = nullptr;
+                    TfLiteRegistrationExternal *registration = nullptr;
+                    TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, delegate_node_id,
+                                                              &node, &registration);
+                    int inputs_size = TfLiteOpaqueNodeNumberOfInputs(node);
+                    for (int k = 0; k < inputs_size; k++) {
+                        const int *inputs_data;
+                        int num_inputs;
+                        TfLiteStatus tf_status =
+                            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+                        const int t = inputs_data[k];
+                        const void *data = nullptr;
+                        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+                        auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+                        if (allocation_type == kTfLiteMmapRo) {
+                            data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                            if (openvino_graph_builder_test->CreateConstNode(opaque_context, t) !=
+                                kTfLiteOk)
+                                exit(0);
+                        }
+                        if (inputs.count(t) != 0) {
+                            if (data == nullptr) {
+                                static int count = 0;
+                                if (count == 0) {
+                                    if (openvino_graph_builder_test->AddInputParams(opaque_tensor,
+                                                                                    t) != kTfLiteOk)
+                                        exit(0);
+                                    compute_inputs_.push_back(t);
+                                    count++;
+                                }
+                            }
+                        }
+                    }
+                    EXPECT_EQ(kTfLiteError,
+                              openvino_graph_builder_test->CreateNodeFromTfLiteOp(
+                                  delegate_node_id, registration, nullptr, opaque_context));
+                }
+
+                openvino_graph_builder_test->UpdateResultNodes(opaque_context, {});
+                std::shared_ptr<ov::Model> model =
+                    std::make_shared<ov::Model>(openvino_graph_builder_test->getResultNodes(),
+                                                openvino_graph_builder_test->getInputParams());
+                ov::Core openvino_delegate_core_;
+                ov::CompiledModel compiled_model_;
+                std::string deviceStr = "CPU";
+                ov::InferRequest infer_request_;
+                if (model) {
+                    compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+                    ov::pass::Manager manager;
+                    manager.register_pass<ov::pass::Serialize>("model.xml", "model.bin");
+                    manager.run_passes(model);
+                }
+
+                infer_request_ = compiled_model_.create_infer_request();
+                return &compiled_model_;
+            });
+
+        TfLiteRegistrationExternalSetInvoke(
+            reg_ex,
+            [](TfLiteOpaqueContext *context, TfLiteOpaqueNode *opaque_node) -> TfLiteStatus {
+                return kTfLiteOk;
+            });
+
+        TfLiteRegistrationExternalSetFree(reg_ex, [](TfLiteOpaqueContext *context, void *data) {});
+
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(opaque_context, reg_ex,
+                                                                 execution_plan, opaque_delegate_);
+        return kTfLiteOk;
+    };
+
+    TfLiteModel *model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+
+    TfLiteOpaqueDelegate *opaque_delegate = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
+
+    EXPECT_TRUE(delegate_prepared);
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    TfLiteOpaqueDelegateDelete(opaque_delegate);
+}
+
+TEST_F(OpenVINOGraphBuilderTest, CreateNodeFromTfLiteOp_InvalidContext) {
+    TfLiteOpaqueDelegateBuilder opaque_delegate_builder{};
+    bool delegate_prepared = false;
+
+    opaque_delegate_builder.data = &delegate_prepared;
+    opaque_delegate_builder.Prepare = [](TfLiteOpaqueContext *opaque_context,
+                                         TfLiteOpaqueDelegate *opaque_delegate_,
+                                         void *data) -> TfLiteStatus {
+        auto delegate_prepared = static_cast<bool *>(data);
+        *delegate_prepared = true;
+        auto reg_ex = TfLiteRegistrationExternalCreate(
+            kTfLiteBuiltinDelegate, "Test driver Openvino delegate", /*version=*/1);
+        TfLiteRegistrationExternalSetInit(
+            reg_ex,
+            [](TfLiteOpaqueContext *opaque_context, const char *buffer, size_t length) -> void * {
+                auto openvino_graph_builder_test =
+                    std::make_unique<tflite::openvinodelegate::OpenVINOGraphBuilder>(
+                        std::make_unique<NodeManager>());
+                std::vector<int> compute_inputs_ = {};
+                std::vector<int> outputs_ = {};
+                const TfLiteOpaqueDelegateParams *params =
+                    reinterpret_cast<const TfLiteOpaqueDelegateParams *>(buffer);
+                const std::unordered_set<int> inputs(
+                    &params->input_tensors->data[0],
+                    &params->input_tensors->data[params->input_tensors->size]);
+
+                for (int o = 0; o < params->output_tensors->size; o++) {
+                    const int output_tensor_idx = params->output_tensors->data[o];
+                    outputs_.push_back(output_tensor_idx);
+                }
+                for (int i = 0; i < params->nodes_to_replace->size; ++i) {
+                    const int delegate_node_id = params->nodes_to_replace->data[i];
+                    TfLiteOpaqueNode *node = nullptr;
+                    TfLiteRegistrationExternal *registration = nullptr;
+                    TfLiteOpaqueContextGetNodeAndRegistration(opaque_context, delegate_node_id,
+                                                              &node, &registration);
+                    int inputs_size = TfLiteOpaqueNodeNumberOfInputs(node);
+                    for (int k = 0; k < inputs_size; k++) {
+                        const int *inputs_data;
+                        int num_inputs;
+                        TfLiteStatus tf_status =
+                            TfLiteOpaqueNodeInputs(node, &inputs_data, &num_inputs);
+                        const int t = inputs_data[k];
+                        const void *data = nullptr;
+                        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(opaque_context, t);
+                        auto allocation_type = TfLiteOpaqueTensorGetAllocationType(opaque_tensor);
+                        if (allocation_type == kTfLiteMmapRo) {
+                            data = TfLiteOpaqueTensorData(opaque_tensor);
+
+                            if (openvino_graph_builder_test->CreateConstNode(opaque_context, t) !=
+                                kTfLiteOk)
+                                exit(0);
+                        }
+                        if (inputs.count(t) != 0) {
+                            if (data == nullptr) {
+                                static int count = 0;
+                                if (count == 0) {
+                                    if (openvino_graph_builder_test->AddInputParams(opaque_tensor,
+                                                                                    t) != kTfLiteOk)
+                                        exit(0);
+                                    compute_inputs_.push_back(t);
+                                    count++;
+                                }
+                            }
+                        }
+                    }
+                    EXPECT_EQ(kTfLiteError, openvino_graph_builder_test->CreateNodeFromTfLiteOp(
+                                                delegate_node_id, registration, node, nullptr));
+                }
+
+                openvino_graph_builder_test->UpdateResultNodes(opaque_context, {});
+                std::shared_ptr<ov::Model> model =
+                    std::make_shared<ov::Model>(openvino_graph_builder_test->getResultNodes(),
+                                                openvino_graph_builder_test->getInputParams());
+                ov::Core openvino_delegate_core_;
+                ov::CompiledModel compiled_model_;
+                std::string deviceStr = "CPU";
+                ov::InferRequest infer_request_;
+                if (model) {
+                    compiled_model_ = openvino_delegate_core_.compile_model(model, deviceStr);
+                    ov::pass::Manager manager;
+                    manager.register_pass<ov::pass::Serialize>("model.xml", "model.bin");
+                    manager.run_passes(model);
+                }
+
+                infer_request_ = compiled_model_.create_infer_request();
+                return &compiled_model_;
+            });
+
+        TfLiteRegistrationExternalSetInvoke(
+            reg_ex,
+            [](TfLiteOpaqueContext *context, TfLiteOpaqueNode *opaque_node) -> TfLiteStatus {
+                return kTfLiteOk;
+            });
+
+        TfLiteRegistrationExternalSetFree(reg_ex, [](TfLiteOpaqueContext *context, void *data) {});
+
+        TfLiteIntArray *execution_plan;
+        TF_LITE_ENSURE_STATUS(TfLiteOpaqueContextGetExecutionPlan(opaque_context, &execution_plan));
+        TfLiteOpaqueContextReplaceNodeSubsetsWithDelegateKernels(opaque_context, reg_ex,
+                                                                 execution_plan, opaque_delegate_);
+        return kTfLiteOk;
+    };
+
+    TfLiteModel *model = TfLiteModelCreateFromFile("tensorflow/lite/testdata/add.bin");
+
+    TfLiteOpaqueDelegate *opaque_delegate = TfLiteOpaqueDelegateCreate(&opaque_delegate_builder);
+    TfLiteInterpreterOptions *options = TfLiteInterpreterOptionsCreate();
+    TfLiteInterpreterOptionsAddDelegate(options, opaque_delegate);
+    TfLiteInterpreter *interpreter = TfLiteInterpreterCreate(model, options);
+
+    EXPECT_TRUE(delegate_prepared);
+
+    TfLiteInterpreterOptionsDelete(options);
+    TfLiteInterpreterDelete(interpreter);
+    TfLiteModelDelete(model);
+    TfLiteOpaqueDelegateDelete(opaque_delegate);
+}
diff --git a/tensorflow/lite/delegates/openvino/operations/BUILD b/tensorflow/lite/delegates/openvino/operations/BUILD
new file mode 100644
index 000000000000..b55db623a451
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/BUILD
@@ -0,0 +1,74 @@
+package(
+    default_visibility = [
+        "//visibility:public",
+    ],
+    licenses = ["notice"],
+)
+
+cc_library(
+    name = "operations_base",
+    srcs = [
+        "src/add.cc",
+        "src/average_pool_2d.cc",
+        "src/conv2d.cc",
+        "src/concat.cc",
+        "src/depthwise_conv2d.cc",
+        "src/dequantize.cc",
+        "src/hardswish.cc",
+        "src/logistic.cc",
+        "src/maxpool2d.cc",
+        "src/mul.cc",
+        "src/mean.cc",
+        "src/relu.cc",
+        "src/relu6.cc",
+        "src/reshape.cc",
+        "src/resize_bilinear.cc",
+        "src/softmax.cc",
+        "src/tanh.cc",
+        "src/transpose_conv.cc",
+    ],
+    hdrs = [
+        "include/add.h",
+        "include/average_pool_2d.h",
+        "include/conv2d.h",
+        "include/concat.h",
+        "include/depthwise_conv2d.h",
+        "include/dequantize.h",
+        "include/hardswish.h",
+        "include/logistic.h",
+        "include/maxpool2d.h",
+        "include/mean.h",
+        "include/mul.h",
+        "include/relu.h",
+        "include/relu6.h",
+        "include/reshape.h",
+        "include/resize_bilinear.h",
+        "include/softmax.h",
+        "include/tanh.h",
+        "include/transpose_conv.h",
+        "operations_base.h",
+        "openvino_node_manager.h",
+    ],
+    tags = [
+        "manual",
+        "nobuilder",
+    ],
+    deps = [
+        "//tensorflow/lite/acceleration/configuration/c:stable_delegate",
+        "//tensorflow/lite:kernel_api",
+        "//tensorflow/lite:util",
+        "//tensorflow/lite/c:c_api",
+        "//tensorflow/lite/c:c_api_experimental",
+        "//tensorflow/lite/c:c_api_types",
+        "//tensorflow/lite/core/c:c_api_types",
+        "//tensorflow/lite/c:common",
+        "//tensorflow/lite/delegates/utils:simple_opaque_delegate",
+	    "//tensorflow/lite/tools:logging",
+        "//tensorflow/lite/kernels:kernel_util",
+        "//tensorflow/lite/kernels:padding",
+        "//tensorflow/lite/kernels/internal:optimized_base",
+        "//tensorflow/lite/kernels/internal:tensor",
+        "//tensorflow/lite/kernels/internal:types",
+        "@intel_openvino//:openvino",
+    ],
+)
diff --git a/tensorflow/lite/delegates/openvino/operations/include/add.h b/tensorflow/lite/delegates/openvino/operations/include/add.h
new file mode 100644
index 000000000000..db5527cdc8dc
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/add.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_ADD_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_ADD_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Add : public OperationsBase {
+public:
+    Add(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_ADD_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/average_pool_2d.h b/tensorflow/lite/delegates/openvino/operations/include/average_pool_2d.h
new file mode 100644
index 000000000000..f63a48dc56a3
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/average_pool_2d.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_AVERAGE_POOL_2D_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_AVERAGE_POOL_2D_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class AveragePool2D : public OperationsBase {
+public:
+    AveragePool2D(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_AVERAGE_POOL_2D_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/concat.h b/tensorflow/lite/delegates/openvino/operations/include/concat.h
new file mode 100644
index 000000000000..bc2ffde4f585
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/concat.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_CONCAT_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_CONCAT_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Concat : public OperationsBase {
+public:
+    Concat(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_CONCAT_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/conv2d.h b/tensorflow/lite/delegates/openvino/operations/include/conv2d.h
new file mode 100644
index 000000000000..23faa57d41d9
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/conv2d.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_CONV2D_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_CONV2D_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Conv2D : public OperationsBase {
+public:
+    Conv2D(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_CONV2D_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/depthwise_conv2d.h b/tensorflow/lite/delegates/openvino/operations/include/depthwise_conv2d.h
new file mode 100644
index 000000000000..8753803cac44
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/depthwise_conv2d.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_DEPTHWISE_CONV2D_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_DEPTHWISE_CONV2D_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class DepthwiseConv2D : public OperationsBase {
+public:
+    DepthwiseConv2D(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_DEPTHWISE_CONV2D_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/dequantize.h b/tensorflow/lite/delegates/openvino/operations/include/dequantize.h
new file mode 100644
index 000000000000..14cfc68e6e30
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/dequantize.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_DEQUANTIZE_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_DEQUANTIZE_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Dequantize : public OperationsBase {
+public:
+    Dequantize(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_DEQUANTIZE_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/hardswish.h b/tensorflow/lite/delegates/openvino/operations/include/hardswish.h
new file mode 100644
index 000000000000..13d9302f4a27
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/hardswish.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_HARDSWISH_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_HARDSWISH_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class HardSwish : public OperationsBase {
+public:
+    HardSwish(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_HARDSWISH_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/logistic.h b/tensorflow/lite/delegates/openvino/operations/include/logistic.h
new file mode 100644
index 000000000000..2c46ab7e8d63
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/logistic.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_LOGISTIC_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_LOGISTIC_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Logistic : public OperationsBase {
+public:
+    Logistic(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_LOGISTIC_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/maxpool2d.h b/tensorflow/lite/delegates/openvino/operations/include/maxpool2d.h
new file mode 100644
index 000000000000..8d6578072a63
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/maxpool2d.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_MAXPOOL2D_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_MAXPOOL2D_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class MaxPool2D : public OperationsBase {
+public:
+    MaxPool2D(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_MAXPOOL2D_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/mean.h b/tensorflow/lite/delegates/openvino/operations/include/mean.h
new file mode 100644
index 000000000000..02df056a5d08
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/mean.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_MEAN_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_MEAN_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Mean : public OperationsBase {
+public:
+    Mean(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_MEAN_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/mul.h b/tensorflow/lite/delegates/openvino/operations/include/mul.h
new file mode 100644
index 000000000000..26a60c97c19e
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/mul.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_MUL_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_MUL_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Mul : public OperationsBase {
+public:
+    Mul(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_MUL_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/relu.h b/tensorflow/lite/delegates/openvino/operations/include/relu.h
new file mode 100644
index 000000000000..fafece7961ec
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/relu.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_RELU_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_RELU_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Relu : public OperationsBase {
+public:
+    Relu(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_RELU_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/relu6.h b/tensorflow/lite/delegates/openvino/operations/include/relu6.h
new file mode 100644
index 000000000000..0e6076d1e596
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/relu6.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_RELU6_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_RELU6_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Relu6 : public OperationsBase {
+public:
+    Relu6(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_RELU6_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/reshape.h b/tensorflow/lite/delegates/openvino/operations/include/reshape.h
new file mode 100644
index 000000000000..d05fd0da79fa
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/reshape.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_RESHAPE_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_RESHAPE_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Reshape : public OperationsBase {
+public:
+    Reshape(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_RESHAPE_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/resize_bilinear.h b/tensorflow/lite/delegates/openvino/operations/include/resize_bilinear.h
new file mode 100644
index 000000000000..90ae09ffc77d
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/resize_bilinear.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_RESIZE_BILINEAR_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_RESIZE_BILINEAR_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class ResizeBilinear : public OperationsBase {
+public:
+    ResizeBilinear(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_RESIZE_BILINEAR_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/softmax.h b/tensorflow/lite/delegates/openvino/operations/include/softmax.h
new file mode 100644
index 000000000000..a7c4be64c6a8
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/softmax.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_SOFTMAX_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_SOFTMAX_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Softmax : public OperationsBase {
+public:
+    Softmax(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_SOFTMAX_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/tanh.h b/tensorflow/lite/delegates/openvino/operations/include/tanh.h
new file mode 100644
index 000000000000..95fe8ca72834
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/tanh.h
@@ -0,0 +1,17 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_TANH_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_TANH_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class Tanh : public OperationsBase {
+public:
+    Tanh(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_TANH_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/include/transpose_conv.h b/tensorflow/lite/delegates/openvino/operations/include/transpose_conv.h
new file mode 100644
index 000000000000..48ea65102e40
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/include/transpose_conv.h
@@ -0,0 +1,21 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_TRANSPOSE_CONV_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_TRANSPOSE_CONV_H_
+
+#include "tensorflow/lite/delegates/openvino/operations/operations_base.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+class TransposeConv : public OperationsBase {
+public:
+    TransposeConv(int operationIndex) {}
+    TfLiteStatus CreateNode() override;
+    void SetCustom(bool isCustom) { isConvolution2dTransposeBias = true; }
+
+private:
+    bool isConvolution2dTransposeBias = false;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_TRANSPOSE_CONV_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/openvino_node_manager.h b/tensorflow/lite/delegates/openvino/operations/openvino_node_manager.h
new file mode 100644
index 000000000000..82229bd02fc7
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/openvino_node_manager.h
@@ -0,0 +1,31 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPENVINO_NODE_MANAGER_H_
+#define TENSORFLOW_LITE_DELEGATES_OPENVINO_NODE_MANAGER_H_
+
+#include <openvino/openvino.hpp>
+
+class NodeManager {
+public:
+    NodeManager() {}
+    std::shared_ptr<ov::Node> getInterimNodeOutput(int index) {
+        auto node = output_at_op_index_[index];
+        return node.get_node_shared_ptr();
+    }
+    void setOutputAtOperandIndex(int index, ov::Output<ov::Node> output) {
+        output_at_op_index_.insert(std::pair<int, ov::Output<ov::Node>>(index, output));
+    }
+
+    size_t getNodeCount() const { return output_at_op_index_.size(); }
+
+    bool isIndexAParam(int index) {
+        if (index_parameters.count(index) > 0)
+            return true;
+        else
+            return false;
+    }
+    void insertIndexParameters(int index) { index_parameters.insert(index); }
+
+private:
+    std::map<int, ov::Output<ov::Node>> output_at_op_index_;
+    std::unordered_set<int> index_parameters;
+};
+#endif  // TENSORFLOW_LITE_DELEGATES_OPENVINO_NODE_MANAGER_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/operations_base.h b/tensorflow/lite/delegates/openvino/operations/operations_base.h
new file mode 100644
index 000000000000..1e472011c36a
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/operations_base.h
@@ -0,0 +1,192 @@
+#ifndef TENSORFLOW_LITE_DELEGATES_OPERATIONS_BASE_H_
+#define TENSORFLOW_LITE_DELEGATES_OPERATIONS_BASE_H_
+
+#include <openvino/openvino.hpp>
+#include <openvino/opsets/opset3.hpp>
+#include <openvino/opsets/opset8.hpp>
+#include "tensorflow/lite/builtin_ops.h"
+#include "tensorflow/lite/c/builtin_op_data.h"
+#include "tensorflow/lite/c/c_api.h"
+#include "tensorflow/lite/c/c_api_opaque.h"
+#include "tensorflow/lite/c/c_api_types.h"
+#include "tensorflow/lite/c/common.h"
+#include "tensorflow/lite/delegates/openvino/operations/openvino_node_manager.h"
+#include "tensorflow/lite/kernels/padding.h"
+#include "tensorflow/lite/tools/logging.h"
+
+#define TFLITE_INPUT_NODE_1 0
+#define TFLITE_INPUT_NODE_2 1
+#define TFLITE_FILTER_NODE 1
+#define TFLITE_BIAS_NODE 2
+#define TFLITE_SHAPE_NODE 1
+#define TFLITE_TRANSPOSE_CONV_OUTPUT_SHAPE 0
+#define TFLITE_TRANSPOSE_CONV_WEIGHTS 1
+#define TFLITE_TRANSPOSE_CONV_INPUT 2
+#define TFLITE_TRANSPOSE_CONV_BIAS 3
+
+namespace tflite {
+namespace openvinodelegate {
+
+class OperationsBase {
+public:
+    void UpdateNodeInfo(void *data, int size, void *builtin_data) {
+        tensor_indices_ = (int *)data;
+        tensor_indices_size_ = size;
+        SetBuiltinData(builtin_data);
+    }
+    void SetGraphData(const TfLiteOpaqueContext *context, NodeManager *node_manager) {
+        context_ = context;
+        node_manager_ = node_manager;
+    }
+
+    std::shared_ptr<ov::Node> GetOpResultNode() { return output_node; }
+    virtual TfLiteStatus CreateNode() = 0;
+
+protected:
+    // tflite runtime related info to be added in Model BUilder
+    int operation_index_;
+    std::shared_ptr<ov::Node> output_node;
+    void *GetBuiltinData() { return builtin_data_; }
+    void SetBuiltinData(void *builtin_data) { builtin_data_ = builtin_data; }
+    std::shared_ptr<ov::Node> getInputNode(int index) {
+        return node_manager_->getInterimNodeOutput(index);
+    }
+    NodeManager *GetGraphNodeManager() { return node_manager_; }
+
+    template <typename T>
+    std::shared_ptr<ov::Node> CreateConstNode(ov::element::Type elementType, ov::Shape shape,
+                                              std::vector<T> data) {
+        return std::make_shared<ov::opset8::Constant>(elementType, shape, data);
+    }
+
+    TfLiteStatus CalculatePadding(TfLitePadding padding, ov::op::PadType &auto_pad) {
+        switch (padding) {
+            case kTfLitePaddingSame: {
+                auto_pad = ov::op::PadType::SAME_UPPER;
+                return kTfLiteOk;
+            }
+            case kTfLitePaddingValid: {
+                auto_pad = ov::op::PadType::VALID;
+                return kTfLiteOk;
+            }
+            default:
+                return kTfLiteError;
+        }
+    }
+
+    std::shared_ptr<ov::Node> ApplyActivation(std::shared_ptr<ov::Node> input,
+                                              TfLiteFusedActivation activation) {
+        // TODO: change activation type from Tflite to OV runtime
+        switch (activation) {
+            case kTfLiteActNone:
+                return input;
+            case kTfLiteActRelu:
+                return std::make_shared<ov::opset8::Relu>(input);
+            case kTfLiteActReluN1To1:
+                return std::make_shared<ov::opset8::Clamp>(input, -1, 1);
+            case kTfLiteActRelu6:
+                return std::make_shared<ov::opset8::Clamp>(input, 0, 6);
+            case kTfLiteActTanh:
+                return std::make_shared<ov::opset8::Tanh>(input);
+            case kTfLiteActSignBit:
+                return nullptr;
+            case kTfLiteActSigmoid:
+                return std::make_shared<ov::opset8::Sigmoid>(input);
+            default:
+                return nullptr;
+        }
+    }
+
+    std::vector<int> GetDims(int index) {
+        auto t = TfLiteOpaqueContextGetOpaqueTensor(context_, index);
+        int32_t num_dims;
+        num_dims = TfLiteOpaqueTensorNumDims(t);
+        std::vector<int> dims(num_dims);
+        for (int i = 0; i < num_dims; i++) {
+            dims[i] = TfLiteOpaqueTensorDim(t, i);
+        }
+        return dims;
+    }
+
+    void GetTensorData(int index, void *data) {
+        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(context_, index);
+        void *tensor_data = TfLiteOpaqueTensorData(opaque_tensor);
+        auto size = TfLiteOpaqueTensorByteSize(opaque_tensor);
+        std::memcpy(data, tensor_data, size);
+    }
+
+    TfLiteStatus GetTensorType(TfLiteOpaqueTensor *t, ov::element::Type *ov_element_type) {
+        TfLiteType tensor_type = TfLiteOpaqueTensorType(t);
+        switch (tensor_type) {
+            case kTfLiteFloat32:
+                *ov_element_type = ov::element::f32;
+                break;
+            case kTfLiteInt32:
+                *ov_element_type = ov::element::i32;
+                break;
+            case kTfLiteUInt8:
+                *ov_element_type = ov::element::u8;
+                break;
+            case kTfLiteInt64:
+                *ov_element_type = ov::element::i64;
+                break;
+            case kTfLiteBool:
+                *ov_element_type = ov::element::boolean;
+                break;
+            case kTfLiteInt16:
+                *ov_element_type = ov::element::i16;
+                break;
+            case kTfLiteInt8:
+                *ov_element_type = ov::element::i8;
+                break;
+            case kTfLiteFloat16:
+                *ov_element_type = ov::element::f16;
+                break;
+            case kTfLiteFloat64:
+                *ov_element_type = ov::element::f64;
+                break;
+            case kTfLiteUInt64:
+                *ov_element_type = ov::element::u64;
+                break;
+            case kTfLiteUInt32:
+                *ov_element_type = ov::element::u32;
+                break;
+            case kTfLiteUInt16:
+                *ov_element_type = ov::element::u16;
+                break;
+            case kTfLiteInt4:
+                *ov_element_type = ov::element::i4;
+                break;
+            default:
+                TFLITE_LOG(ERROR) << "Element type not supported\n";
+                return kTfLiteError;
+        }
+        return kTfLiteOk;
+    }
+
+    void *GetTensorDataPtrAndSize(int index, unsigned int *size) {
+        auto opaque_tensor = TfLiteOpaqueContextGetOpaqueTensor(context_, index);
+        void *tensor_data = TfLiteOpaqueTensorData(opaque_tensor);
+        ov::element::Type ov_element_type;
+
+        if (GetTensorType(opaque_tensor, &ov_element_type) != kTfLiteOk) {
+            *size = 0;
+            return nullptr;
+        }
+        *size = TfLiteOpaqueTensorByteSize(opaque_tensor) / sizeof(ov_element_type);
+        return tensor_data;
+    }
+
+    int *tensor_indices_;
+    int tensor_indices_size_;
+
+private:
+    void *builtin_data_ = nullptr;
+    int op_type_ = 0;
+    NodeManager *node_manager_;
+    const TfLiteOpaqueContext *context_;
+};
+
+}  // namespace openvinodelegate
+}  // namespace tflite
+#endif  // TENSORFLOW_LITE_DELEGATES_OPERATIOSN_BASE_H_
diff --git a/tensorflow/lite/delegates/openvino/operations/src/add.cc b/tensorflow/lite/delegates/openvino/operations/src/add.cc
new file mode 100644
index 000000000000..ccef9635de6e
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/add.cc
@@ -0,0 +1,26 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/add.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Add::CreateNode() {
+    TfLiteAddParams *add_params = (TfLiteAddParams *)GetBuiltinData();
+    auto input_node_1 = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node_1 == nullptr) {
+        TFLITE_LOG(INFO) << "input node 1 is null\n";
+        return kTfLiteError;
+    }
+    auto input_node_2 = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_2]);
+    if (input_node_2 == nullptr) {
+        TFLITE_LOG(INFO) << "input Node 2 is null\n";
+        return kTfLiteError;
+    }
+
+    auto add_node = std::make_shared<ov::opset8::Add>(input_node_1, input_node_2,
+                                                      ov::op::AutoBroadcastType::NUMPY);
+    output_node = ApplyActivation(add_node, add_params->activation);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/average_pool_2d.cc b/tensorflow/lite/delegates/openvino/operations/src/average_pool_2d.cc
new file mode 100644
index 000000000000..d07a0a7e6a2b
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/average_pool_2d.cc
@@ -0,0 +1,40 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/average_pool_2d.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus AveragePool2D::CreateNode() {
+    TfLitePoolParams *avg_pool_params = (TfLitePoolParams *)GetBuiltinData();
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        TFLITE_LOG(ERROR) << "input node is null\n";
+        return kTfLiteError;
+    }
+
+    std::vector<size_t> strides;
+    std::vector<size_t> kernel;
+    std::vector<size_t> padding_begin, padding_end;
+    ov::op::PadType auto_pad;
+    size_t padding_top, padding_bottom, padding_left, padding_right = 0;
+
+    TfLiteStatus tf_status = CalculatePadding(avg_pool_params->padding, auto_pad);
+    if (tf_status == kTfLiteError) {
+        TFLITE_LOG(ERROR) << "Invalid Padding\n";
+        return kTfLiteError;
+    }
+
+    strides = {(size_t)avg_pool_params->stride_height, (size_t)avg_pool_params->stride_width};
+    kernel = {(size_t)avg_pool_params->filter_height, (size_t)avg_pool_params->filter_width};
+    padding_begin = {padding_top, padding_left};
+    padding_end = {padding_bottom, padding_right};
+
+    auto average_pool_2d_node = std::make_shared<ov::opset8::AvgPool>(
+        input_node, ov::Strides(strides), ov::Shape(padding_begin), ov::Shape(padding_end),
+        ov::Shape(kernel), true, ov::op::RoundingType::FLOOR, auto_pad);
+    output_node = ApplyActivation(average_pool_2d_node, avg_pool_params->activation);
+
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/concat.cc b/tensorflow/lite/delegates/openvino/operations/src/concat.cc
new file mode 100644
index 000000000000..00197dd047c6
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/concat.cc
@@ -0,0 +1,36 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/concat.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Concat::CreateNode() {
+    TfLiteConcatenationParams *concat_params = (TfLiteConcatenationParams *)GetBuiltinData();
+    auto inputNode1 = getInputNode(tensor_indices_[0]);
+    if (inputNode1 == nullptr) {
+        TFLITE_LOG(INFO) << "input node 1 is null\n";
+        return kTfLiteError;
+    }
+
+    auto inputNode2 = getInputNode(tensor_indices_[1]);
+    if (inputNode2 == nullptr) {
+        TFLITE_LOG(INFO) << "input Node 2 is null\n";
+        return kTfLiteError;
+    }
+
+    // TODO: Replace the hard coded value with logic.
+    int axis = 1;
+    size_t n = tensor_indices_size_;
+    std::vector<ov::Output<ov::Node>> inputs;
+    for (size_t i = 0; i < n; i++) {
+        auto inputOp = getInputNode(tensor_indices_[i]);
+        inputs.push_back(inputOp);
+    }
+
+    auto concatNode = std::make_shared<ov::opset8::Concat>(inputs, axis);
+    output_node = ApplyActivation(concatNode, concat_params->activation);
+
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/conv2d.cc b/tensorflow/lite/delegates/openvino/operations/src/conv2d.cc
new file mode 100644
index 000000000000..1428645c3edf
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/conv2d.cc
@@ -0,0 +1,56 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/conv2d.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Conv2D::CreateNode() {
+    const TfLiteConvParams *conv2d_params = (TfLiteConvParams *)GetBuiltinData();
+    std::vector<int> filter_dims = GetDims(tensor_indices_[TFLITE_FILTER_NODE]);
+    std::vector<size_t> strides;
+    std::vector<std::ptrdiff_t> padding_begin, padding_end;
+    std::vector<size_t> dilations;
+    ov::op::PadType auto_pad;
+    int filter_size = 0;
+    int padding_top, padding_bottom, padding_left, padding_right = 0;
+
+    TfLiteStatus status = CalculatePadding(conv2d_params->padding, auto_pad);
+    if (status != kTfLiteOk) {
+        TFLITE_LOG(ERROR) << "Invalid padding type in conv2d\n";
+        return kTfLiteError;
+    }
+
+    strides = {(size_t)conv2d_params->stride_height, (size_t)conv2d_params->stride_width};
+    padding_begin = {padding_top, padding_left};
+    padding_end = {padding_bottom, padding_right};
+    dilations = {(size_t)conv2d_params->dilation_height_factor,
+                 (size_t)conv2d_params->dilation_width_factor};
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    auto filter_node = getInputNode(tensor_indices_[TFLITE_FILTER_NODE]);
+    auto bias_node = getInputNode(tensor_indices_[TFLITE_BIAS_NODE]);
+
+    if (!GetGraphNodeManager()->isIndexAParam(tensor_indices_[TFLITE_FILTER_NODE])) {
+        ov::AxisVector order = {0, 3, 1, 2};
+        const auto order_node =
+            ov::opset3::Constant::create(ov::element::i64, ov::Shape{order.size()}, order);
+        filter_node = std::make_shared<ov::opset3::Transpose>(filter_node, order_node);
+    }
+
+    auto conv_node = std::make_shared<ov::opset8::Convolution>(
+        input_node, filter_node, ov::Strides(strides), ov::CoordinateDiff(padding_begin),
+        ov::CoordinateDiff(padding_end), ov::Strides(dilations), auto_pad);
+    auto bias_dims = GetDims(tensor_indices_[TFLITE_BIAS_NODE]);
+    std::vector<uint32_t> shape(conv_node->get_shape().size(), 1);
+    shape[1] = bias_dims[0];
+    auto shape_node = CreateConstNode(ov::element::i32, ov::Shape{shape.size()}, shape);
+
+    bias_node = std::make_shared<ov::opset3::Reshape>(bias_node, shape_node, true);
+
+    output_node =
+        std::make_shared<ov::opset3::Add>(conv_node, bias_node, ov::op::AutoBroadcastType::NUMPY);
+
+    output_node = ApplyActivation(output_node, conv2d_params->activation);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/depthwise_conv2d.cc b/tensorflow/lite/delegates/openvino/operations/src/depthwise_conv2d.cc
new file mode 100644
index 000000000000..1f451aa71888
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/depthwise_conv2d.cc
@@ -0,0 +1,70 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/depthwise_conv2d.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus DepthwiseConv2D::CreateNode() {
+    const TfLiteDepthwiseConvParams *depth_conv2dParams =
+        (TfLiteDepthwiseConvParams *)GetBuiltinData();
+    // TODO: check for datatypes, tensor shapes, and non dynamic allocation
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    auto filter_node = getInputNode(tensor_indices_[TFLITE_FILTER_NODE]);
+    bool has_bias = false;
+    ov::Output<ov::Node> bias_node;
+    std::vector<size_t> strides = {(size_t)depth_conv2dParams->stride_height,
+                                   (size_t)depth_conv2dParams->stride_width};
+    std::vector<size_t> dilations = {(size_t)depth_conv2dParams->dilation_height_factor,
+                                     (size_t)depth_conv2dParams->dilation_width_factor};
+    if (tensor_indices_[TFLITE_BIAS_NODE] < 0) {
+        has_bias = false;
+    } else {
+        bias_node = getInputNode(tensor_indices_[TFLITE_BIAS_NODE]);
+        has_bias = true;
+    }
+
+    ov::op::PadType auto_pad;
+    auto input_dims = GetDims(tensor_indices_[TFLITE_INPUT_NODE_1]);
+
+    TfLiteStatus status = CalculatePadding(depth_conv2dParams->padding, auto_pad);
+    if (status != kTfLiteOk) {
+        TFLITE_LOG(ERROR) << "Invalid padding type in depthwise conv2d\n";
+        return kTfLiteError;
+    }
+
+    ov::AxisVector order = {3, 0, 1, 2};
+    // Uncomment below line and comment above line for test mode
+    // ov::AxisVector order = {1,0,2,3};
+    const auto order_node =
+        std::make_shared<ov::opset8::Constant>(ov::element::i64, ov::Shape{order.size()}, order);
+    filter_node = std::make_shared<ov::opset3::Transpose>(filter_node, order_node);
+
+    std::vector<size_t> shape(&filter_node->get_shape()[0], &filter_node->get_shape()[0] + 4);
+    auto num_groups = input_dims[3] / filter_node->get_shape()[1];
+    shape.insert(shape.begin(), num_groups);
+    shape[1] = filter_node->get_shape()[0] / num_groups;
+    auto shape_node = CreateConstNode(ov::element::i32, ov::Shape{shape.size()}, shape);
+
+    filter_node = std::make_shared<ov::opset3::Reshape>(filter_node, shape_node, true);
+
+    auto depthwise_conv_node = std::make_shared<ov::opset3::GroupConvolution>(
+        input_node, filter_node, ov::Strides(strides), ov::CoordinateDiff(0, 0),
+        ov::CoordinateDiff(0, 0), ov::Strides(dilations), auto_pad);
+
+    if (has_bias) {
+        auto bias_dimensions = GetDims(tensor_indices_[TFLITE_BIAS_NODE]);
+        std::vector<uint32_t> shape(depthwise_conv_node->get_shape().size(), 1);
+        shape[1] = bias_dimensions[0];
+        auto shape_node = CreateConstNode(ov::element::i32, ov::Shape{shape.size()}, shape);
+        bias_node = std::make_shared<ov::opset3::Reshape>(bias_node, shape_node, true);
+        output_node = std::make_shared<ov::opset3::Add>(depthwise_conv_node, bias_node,
+                                                        ov::op::AutoBroadcastType::NUMPY);
+    } else {
+        output_node = depthwise_conv_node;
+    }
+
+    output_node = ApplyActivation(output_node, depth_conv2dParams->activation);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/dequantize.cc b/tensorflow/lite/delegates/openvino/operations/src/dequantize.cc
new file mode 100644
index 000000000000..94d44c1a9f6d
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/dequantize.cc
@@ -0,0 +1,19 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/dequantize.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Dequantize::CreateNode() {
+    auto inputNode = getInputNode(tensor_indices_[0]);
+    if (inputNode == nullptr) {
+        TFLITE_LOG(INFO) << "input node  is null\n";
+        return kTfLiteError;
+    }
+
+    output_node = std::make_shared<ov::opset8::Convert>(inputNode, ov::element::f32);
+
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/hardswish.cc b/tensorflow/lite/delegates/openvino/operations/src/hardswish.cc
new file mode 100644
index 000000000000..1902c03eafa7
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/hardswish.cc
@@ -0,0 +1,16 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/hardswish.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus HardSwish::CreateNode() {
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        return kTfLiteError;
+    }
+    output_node = std::make_shared<ov::op::v4::HSwish>(input_node);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/logistic.cc b/tensorflow/lite/delegates/openvino/operations/src/logistic.cc
new file mode 100644
index 000000000000..0d441367d9ec
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/logistic.cc
@@ -0,0 +1,17 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/logistic.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Logistic::CreateNode() {
+    // Creating input nodes
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        return kTfLiteError;
+    }
+    output_node = ApplyActivation(input_node, kTfLiteActSigmoid);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/maxpool2d.cc b/tensorflow/lite/delegates/openvino/operations/src/maxpool2d.cc
new file mode 100644
index 000000000000..debc95b17108
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/maxpool2d.cc
@@ -0,0 +1,38 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/maxpool2d.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus MaxPool2D::CreateNode() {
+    const TfLitePoolParams *maxpool2d_params = (TfLitePoolParams *)GetBuiltinData();
+
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+
+    std::vector<size_t> strides{(size_t)maxpool2d_params->stride_height,
+                                (size_t)maxpool2d_params->stride_width};
+
+    // will be ignored since auto_pad is specified
+    std::vector<std::size_t> padding_begin = {0, 0};
+    std::vector<std::size_t> padding_end = {0, 0};
+    // ToDo: According to tf release note:
+    // `tf.nn.max_pool2d` now supports explicit padding.
+    // need to support.
+
+    std::vector<size_t> kernel{(size_t)maxpool2d_params->filter_height,
+                               (size_t)maxpool2d_params->filter_width};
+
+    // Set padding scheme to PadType::VALID for valid or unknown
+    ov::op::PadType auto_pad = (maxpool2d_params->padding == kTfLitePaddingSame)
+                                   ? ov::op::PadType::SAME_UPPER
+                                   : ov::op::PadType::VALID;
+
+    auto maxpool2d_node = std::make_shared<ov::opset3::MaxPool>(
+        input_node, ov::Strides(strides), ov::Shape(padding_begin), ov::Shape(padding_end),
+        ov::Shape(kernel), ov::op::RoundingType::FLOOR, auto_pad);
+
+    output_node = ApplyActivation(maxpool2d_node, maxpool2d_params->activation);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/mean.cc b/tensorflow/lite/delegates/openvino/operations/src/mean.cc
new file mode 100644
index 000000000000..74dc6ba6e6e2
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/mean.cc
@@ -0,0 +1,54 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/mean.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Mean::CreateNode() {
+    TfLiteReducerParams *reduce_params = (TfLiteReducerParams *)GetBuiltinData();
+
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        TFLITE_LOG(INFO) << "input node is null\n";
+        return kTfLiteError;
+    }
+
+    std::shared_ptr<ov::Node> reduction_axes = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_2]);
+    if (reduction_axes == nullptr) {
+        TFLITE_LOG(INFO) << "reduction_axes is null\n";
+        return kTfLiteError;
+    }
+
+    std::vector<int32_t> axes_vec = {};
+    unsigned int size;
+    void *data = GetTensorDataPtrAndSize(tensor_indices_[1], &size);
+    if (size == 0 or data == nullptr) {
+        TFLITE_LOG(INFO) << "Failed to get reduction_axes data\n";
+        return kTfLiteError;
+    }
+
+    for (auto i = 0; i < size; i++) {
+        int ax = *((int *)(data) + i);
+        if (ax == 1)
+            axes_vec.push_back(2);
+        else if (ax == 2)
+            axes_vec.push_back(3);
+        else if (ax == 3)
+            axes_vec.push_back(1);
+        else
+            axes_vec.push_back(ax);
+    }
+
+    auto axes_node = CreateConstNode(ov::element::i32, {size}, axes_vec);
+    if (axes_node == nullptr) {
+        TFLITE_LOG(INFO) << "Failed to create const node for axes\n";
+        return kTfLiteError;
+    }
+
+    bool keep_dims = (reduce_params->keep_dims > 0) ? true : false;
+    output_node = std::make_shared<ov::op::v1::ReduceMean>(input_node, axes_node, keep_dims);
+
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/mul.cc b/tensorflow/lite/delegates/openvino/operations/src/mul.cc
new file mode 100644
index 000000000000..5e6d0b7255b5
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/mul.cc
@@ -0,0 +1,26 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/mul.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Mul::CreateNode() {
+    TfLiteMulParams *mul_params = (TfLiteMulParams *)GetBuiltinData();
+    auto input_node_1 = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node_1 == nullptr) {
+        TFLITE_LOG(INFO) << "input node 1 is null\n";
+        return kTfLiteError;
+    }
+    auto input_node_2 = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_2]);
+    if (input_node_2 == nullptr) {
+        TFLITE_LOG(INFO) << "input Node 2 is null\n";
+        return kTfLiteError;
+    }
+
+    auto mul_node = std::make_shared<ov::opset3::Multiply>(input_node_1, input_node_2,
+                                                           ov::op::AutoBroadcastType::NUMPY);
+    output_node = ApplyActivation(mul_node, mul_params->activation);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/relu.cc b/tensorflow/lite/delegates/openvino/operations/src/relu.cc
new file mode 100644
index 000000000000..99bb1e3cf63d
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/relu.cc
@@ -0,0 +1,16 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/relu.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Relu::CreateNode() {
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        return kTfLiteError;
+    }
+    output_node = ApplyActivation(input_node, kTfLiteActRelu);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/relu6.cc b/tensorflow/lite/delegates/openvino/operations/src/relu6.cc
new file mode 100644
index 000000000000..d8ef8894341c
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/relu6.cc
@@ -0,0 +1,16 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/relu6.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Relu6::CreateNode() {
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        return kTfLiteError;
+    }
+    output_node = ApplyActivation(input_node, kTfLiteActRelu6);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/reshape.cc b/tensorflow/lite/delegates/openvino/operations/src/reshape.cc
new file mode 100644
index 000000000000..ccf87111f8ac
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/reshape.cc
@@ -0,0 +1,30 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/reshape.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Reshape::CreateNode() {
+    // arg - input node
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        TFLITE_LOG(ERROR) << "input node is null\n";
+        return kTfLiteError;
+    }
+
+    // shape_pattern - shape node
+    ov::Output<ov::Node> shape_node = getInputNode(tensor_indices_[TFLITE_SHAPE_NODE]);
+
+    // special_zero
+    // Set false since Keras doesn't have special_zero argument
+
+    output_node = std::make_shared<ov::opset3::Reshape>(input_node, shape_node, false);
+    if (output_node == nullptr) {
+        TFLITE_LOG(ERROR) << "output node is null\n";
+        return kTfLiteError;
+    }
+
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/resize_bilinear.cc b/tensorflow/lite/delegates/openvino/operations/src/resize_bilinear.cc
new file mode 100644
index 000000000000..8fb261e5e691
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/resize_bilinear.cc
@@ -0,0 +1,40 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/resize_bilinear.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus ResizeBilinear::CreateNode() {
+    const TfLiteResizeBilinearParams *resize_bilinearParams =
+        (TfLiteResizeBilinearParams *)GetBuiltinData();
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    auto shape_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_2]);
+    struct ov::op::v11::Interpolate::InterpolateAttrs attrs;
+
+    attrs.mode = ov::op::v11::Interpolate::InterpolateMode::LINEAR_ONNX;
+    attrs.shape_calculation_mode = ov::op::v11::Interpolate::ShapeCalcMode::SIZES;
+
+    if (resize_bilinearParams->align_corners == true) {
+        attrs.coordinate_transformation_mode =
+            ov::op::v11::Interpolate::CoordinateTransformMode::ALIGN_CORNERS;
+    } else if (resize_bilinearParams->half_pixel_centers == true) {
+        attrs.coordinate_transformation_mode =
+            ov::op::v11::Interpolate::CoordinateTransformMode::HALF_PIXEL;
+    } else {
+        attrs.coordinate_transformation_mode =
+            ov::op::v11::Interpolate::CoordinateTransformMode::ASYMMETRIC;
+    }
+
+    std::vector<int32_t> axes_vec = {2, 3};
+    auto axes_node = CreateConstNode(ov::element::i32, {2}, axes_vec);
+    if (axes_node == nullptr) {
+        TFLITE_LOG(INFO) << "axes node is null \n";
+        return kTfLiteError;
+    }
+
+    output_node =
+        std::make_shared<ov::op::v11::Interpolate>(input_node, shape_node, axes_node, attrs);
+
+    return kTfLiteOk;
+}
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/softmax.cc b/tensorflow/lite/delegates/openvino/operations/src/softmax.cc
new file mode 100644
index 000000000000..10efa2a2fcbf
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/softmax.cc
@@ -0,0 +1,22 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/softmax.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Softmax::CreateNode() {
+    TfLiteSoftmaxParams *softmax_params = (TfLiteSoftmaxParams *)GetBuiltinData();
+    auto input_node_1 = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node_1 == nullptr) {
+        TFLITE_LOG(INFO) << "input node 1 is null\n";
+        return kTfLiteError;
+    }
+
+    // NOTE: assumption here is: Tensorflow always computes softmax along
+    // channel(last) dimesnsion. After transpose, our channel shifts to dim 1,
+    // which is default axis attribute for Softmax.
+    output_node = std::make_shared<ov::opset8::Softmax>(input_node_1);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/tanh.cc b/tensorflow/lite/delegates/openvino/operations/src/tanh.cc
new file mode 100644
index 000000000000..2fcea591914d
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/tanh.cc
@@ -0,0 +1,18 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/tanh.h"
+
+namespace tflite {
+namespace openvinodelegate {
+
+TfLiteStatus Tanh::CreateNode() {
+    auto input_node = getInputNode(tensor_indices_[TFLITE_INPUT_NODE_1]);
+    if (input_node == nullptr) {
+        TFLITE_LOG(ERROR) << "input node is null\n";
+        return kTfLiteError;
+    }
+
+    output_node = ApplyActivation(input_node, kTfLiteActTanh);
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations/src/transpose_conv.cc b/tensorflow/lite/delegates/openvino/operations/src/transpose_conv.cc
new file mode 100644
index 000000000000..de43fd91e828
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/operations/src/transpose_conv.cc
@@ -0,0 +1,95 @@
+#include "tensorflow/lite/delegates/openvino/operations/include/transpose_conv.h"
+
+namespace tflite {
+namespace openvinodelegate {
+TfLiteStatus TransposeConv::CreateNode() {
+    const TfLiteTransposeConvParams *transpose_conv_params =
+        (TfLiteTransposeConvParams *)GetBuiltinData();
+    std::shared_ptr<ov::Node> weights_node = nullptr;
+    std::shared_ptr<ov::Node> input_node = nullptr;
+    if (!isConvolution2dTransposeBias) {
+        weights_node = getInputNode(tensor_indices_[TFLITE_TRANSPOSE_CONV_WEIGHTS]);
+        input_node = getInputNode(tensor_indices_[TFLITE_TRANSPOSE_CONV_INPUT]);
+    } else {
+        input_node = getInputNode(tensor_indices_[0]);
+        weights_node = getInputNode(tensor_indices_[1]);
+    }
+    bool has_bias = false;
+    std::shared_ptr<ov::Node> bias_node = nullptr;
+    if (!isConvolution2dTransposeBias) {
+        if (tensor_indices_size_ >= 4) {
+            bias_node = getInputNode(tensor_indices_[TFLITE_TRANSPOSE_CONV_BIAS]);
+            has_bias = true;
+        }
+    } else {
+        bias_node = getInputNode(tensor_indices_[2]);
+        has_bias = true;
+    }
+    std::vector<size_t> strides = {(size_t)transpose_conv_params->stride_height,
+                                   (size_t)transpose_conv_params->stride_width};
+    size_t dilation_width_factor = 1.0, dilation_height_factor = 1.0;
+    std::vector<size_t> dilations = {dilation_height_factor, dilation_width_factor};
+    ov::op::PadType auto_pad = ov::op::PadType::SAME_UPPER;
+    int padding_top = 0, padding_bottom = 0, padding_left = 0, padding_right = 0;
+
+    if (transpose_conv_params->padding == kTfLitePaddingUnknown) {
+    } else if (transpose_conv_params->padding == kTfLitePaddingSame) {
+        auto_pad = ov::op::PadType::SAME_UPPER;
+    } else if (transpose_conv_params->padding == kTfLitePaddingValid) {
+        auto_pad = ov::op::PadType::VALID;
+    }
+
+    std::vector<std::ptrdiff_t> padding_begin = {padding_top, padding_left};
+    std::vector<std::ptrdiff_t> padding_end = {padding_bottom, padding_right};
+
+    // Comment below transpose lines for test mode
+    ov::AxisVector order = {3, 0, 1, 2};
+    const auto order_node =
+        ov::opset3::Constant::create(ov::element::i64, ov::Shape{order.size()}, order);
+    weights_node = std::make_shared<ov::opset3::Transpose>(weights_node, order_node);
+
+    std::shared_ptr<ov::Node> transpose_conv_node = nullptr;
+    size_t spatial_dimensions_size = 2;
+    int32_t output_shape[4];
+    std::vector<int32_t> spatial_dimensions(spatial_dimensions_size);
+    if (!isConvolution2dTransposeBias) {
+        GetTensorData(tensor_indices_[0], &output_shape);
+        spatial_dimensions[0] = output_shape[1];
+        spatial_dimensions[1] = output_shape[2];
+    } else {
+        std::vector<int32_t> conv_output_shape = GetDims(tensor_indices_[0]);
+        spatial_dimensions[0] = conv_output_shape[1] * 2;
+        spatial_dimensions[1] = conv_output_shape[2] * 2;
+    }
+    auto output_shape_node = std::make_shared<ov::opset8::Constant>(
+        ov::element::i32, ov::Shape{spatial_dimensions_size}, spatial_dimensions);
+
+    transpose_conv_node = std::make_shared<ov::opset3::ConvolutionBackpropData>(
+        input_node, weights_node, output_shape_node, ov::Strides(strides),
+        ov::CoordinateDiff(padding_begin), ov::CoordinateDiff(padding_end), ov::Strides(dilations),
+        auto_pad);
+
+    if (has_bias) {
+        std::vector<int> bias_dims;
+        if (!isConvolution2dTransposeBias) {
+            bias_dims = GetDims(tensor_indices_[TFLITE_TRANSPOSE_CONV_BIAS]);
+        } else {
+            bias_dims = GetDims(tensor_indices_[2]);
+        }
+        std::vector<uint32_t> shape(transpose_conv_node->get_shape().size(), 1);
+        shape[1] = bias_dims[0];
+        auto shape_node = CreateConstNode(ov::element::i32, ov::Shape{shape.size()}, shape);
+        bias_node = std::make_shared<ov::opset3::Reshape>(bias_node, shape_node, true);
+        output_node = std::make_shared<ov::opset3::Add>(transpose_conv_node, bias_node,
+                                                        ov::op::AutoBroadcastType::NUMPY);
+    } else {
+        output_node = transpose_conv_node;
+    }
+    if (!isConvolution2dTransposeBias) {
+        output_node = ApplyActivation(output_node, transpose_conv_params->activation);
+    }
+    return kTfLiteOk;
+}
+
+}  // namespace openvinodelegate
+}  // namespace tflite
diff --git a/tensorflow/lite/delegates/openvino/operations_base.cc b/tensorflow/lite/delegates/openvino/operations_base.cc
new file mode 100644
index 000000000000..e69de29bb2d1
diff --git a/tensorflow/lite/delegates/openvino/stable_delegate_settings.json b/tensorflow/lite/delegates/openvino/stable_delegate_settings.json
new file mode 100644
index 000000000000..89aefe326fa2
--- /dev/null
+++ b/tensorflow/lite/delegates/openvino/stable_delegate_settings.json
@@ -0,0 +1,6 @@
+{
+  "stable_delegate_loader_settings": {
+    "delegate_path": "bazel-bin/tensorflow/lite/delegates/openvino/libtensorflowlite_openvino_stable_delegate.so"
+  }
+  // Add concrete delegate settings for the openvino delegate.
+}
diff --git a/tensorflow/lite/tflite_with_openvino.cc b/tensorflow/lite/tflite_with_openvino.cc
new file mode 100644
index 000000000000..cb690e473b15
--- /dev/null
+++ b/tensorflow/lite/tflite_with_openvino.cc
@@ -0,0 +1,14 @@
+#include <memory>
+
+#include "tensorflow/lite/c/common.h"
+#include "tensorflow/lite/delegates/openvino/openvino_delegate.h"
+
+namespace tflite {
+std::unique_ptr<TfLiteDelegate, void (*)(TfLiteDelegate*)>
+AcquireOPENVINODelegate(int num_threads) {
+  auto opts = TfLiteOpenVINODelegateOptionsDefault();
+  // Note that we don't want to use the thread pool for num_threads == 1.
+ return std::unique_ptr<TfLiteDelegate, void (*)(TfLiteDelegate*)>(
+      TfLiteCreateOpenVINODelegate(&opts), TfLiteDeleteOpenVINODelegate);
+}
+}  // namespace tflite
diff --git a/tensorflow/lite/tools/delegates/BUILD b/tensorflow/lite/tools/delegates/BUILD
index a6ba60436ebc..1d9975a8e59e 100644
--- a/tensorflow/lite/tools/delegates/BUILD
+++ b/tensorflow/lite/tools/delegates/BUILD
@@ -47,13 +47,13 @@ cc_library_with_tflite(
         ":delegate_provider_lib",
     ],
     deps = [
-        ":coreml_delegate_provider",
-        ":default_execution_provider",
-        ":external_delegate_provider",
-        ":gpu_delegate_provider",
-        ":hexagon_delegate_provider",
-        ":nnapi_delegate_provider",
-        "//tensorflow/lite/tools/delegates/experimental/stable_delegate:delegate_provider",
+	":coreml_delegate_provider",
+	":default_execution_provider",
+	":hexagon_delegate_provider",
+    ":external_delegate_provider",
+	":gpu_delegate_provider",
+    ":nnapi_delegate_provider",
+    "//tensorflow/lite/tools/delegates/experimental/stable_delegate:delegate_provider",
     ],
     alwayslink = 1,
 )
@@ -87,10 +87,10 @@ cc_library(
         "//tensorflow/lite/tools/evaluation:utils",
     ] + select({
         "//tensorflow/lite/delegates/gpu:supports_gpu_delegate": [
-            "//tensorflow/lite/delegates/gpu:delegate",
+        "//tensorflow/lite/delegates/gpu:delegate",
         ],
         "//conditions:default": [],
-    }) + select({
+      }) + select({
         "//tensorflow:ios": [
             "//tensorflow/lite/delegates/gpu:metal_delegate",
         ],
@@ -136,7 +136,7 @@ cc_library(
 cc_library(
     name = "coreml_delegate_provider",
     srcs = ["coreml_delegate_provider.cc"],
-    copts = common_copts + select({
+    copts = common_copts + ["-fexceptions"] + select({
         "//tensorflow:ios": [
             "-xobjective-c++",
         ],
@@ -163,7 +163,7 @@ cc_library(
 cc_library_with_tflite(
     name = "xnnpack_delegate_provider",
     srcs = ["xnnpack_delegate_provider.cc"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ["-fexceptions"],
     linkstatic = True,
     tflite_deps = [
         ":delegate_provider_hdr",
@@ -173,6 +173,20 @@ cc_library_with_tflite(
     alwayslink = 1,
 )
 
+cc_library(
+    name = "openvino_delegate_provider",
+    srcs = ["openvino_delegate_provider.cc"],
+    copts = tflite_copts() + ["-fexceptions"],
+    linkstatic = True,
+    visibility = ["//visibility:public"],
+    deps = [
+        ":delegate_provider_hdr",
+       "//tensorflow/lite/delegates/openvino:openvino_delegate",
+    ],
+    alwayslink = 1,
+)
+
+
 cc_library(
     name = "external_delegate_provider",
     srcs = ["external_delegate_provider.cc"],
diff --git a/tensorflow/lite/tools/delegates/openvino_delegate_provider.cc b/tensorflow/lite/tools/delegates/openvino_delegate_provider.cc
new file mode 100644
index 000000000000..7b6c4fb47a0b
--- /dev/null
+++ b/tensorflow/lite/tools/delegates/openvino_delegate_provider.cc
@@ -0,0 +1,63 @@
+#include <string>
+#include <utility>
+
+#include "tensorflow/lite/tools/delegates/delegate_provider.h"
+#include "tensorflow/lite/tools/evaluation/utils.h"
+
+namespace tflite {
+namespace tools {
+
+class OpenVINODelegateProvider : public DelegateProvider {
+ public:
+  OpenVINODelegateProvider() {
+    default_params_.AddParam("use_openvino", ToolParam::Create<bool>(false));
+  }
+
+  std::vector<Flag> CreateFlags(ToolParams* params) const final;
+
+  void LogParams(const ToolParams& params, bool verbose) const final;
+
+  TfLiteDelegatePtr CreateTfLiteDelegate(const ToolParams& params) const final;
+  std::pair<TfLiteDelegatePtr, int> CreateRankedTfLiteDelegate(
+      const ToolParams& params) const final;
+
+  std::string GetName() const final { return "OPENVINO"; }
+};
+REGISTER_DELEGATE_PROVIDER(OpenVINODelegateProvider);
+
+std::vector<Flag> OpenVINODelegateProvider::CreateFlags(
+    ToolParams* params) const {
+  std::vector<Flag> flags = {CreateFlag<bool>(
+      "use_openvino", params,
+      "explicitly apply the OPENVINO delegate. Note the OPENVINO delegate could "
+      "be implicitly applied by the TF Lite runtime regardless the value of "
+      "this parameter. To disable this implicit application, set the value to "
+      "false explicitly.")};
+  return flags;
+}
+
+void OpenVINODelegateProvider::LogParams(const ToolParams& params,
+                                        bool verbose) const {
+  LOG_TOOL_PARAM(params, bool, "use_openvino", "Use openvino", verbose);
+}
+
+
+//TODO
+TfLiteDelegatePtr OpenVINODelegateProvider::CreateTfLiteDelegate(
+    const ToolParams& params) const {
+  if (params.Get<bool>("use_openvino"))
+    return ::tflite::evaluation::CreateOPENVINODelegate();
+  else
+    return TfLiteDelegatePtr(nullptr, [](TfLiteDelegate*) {});
+}
+
+std::pair<TfLiteDelegatePtr, int>
+OpenVINODelegateProvider::CreateRankedTfLiteDelegate(
+    const ToolParams& params) const {
+  auto ptr = CreateTfLiteDelegate(params);
+  return std::make_pair(std::move(ptr),
+                        params.GetPosition<bool>("use_openvino"));
+}
+}  // namespace tflite
+
+}  // namespace tools
diff --git a/tensorflow/lite/tools/evaluation/BUILD b/tensorflow/lite/tools/evaluation/BUILD
index 227f760d01a1..681570539ae8 100644
--- a/tensorflow/lite/tools/evaluation/BUILD
+++ b/tensorflow/lite/tools/evaluation/BUILD
@@ -40,7 +40,7 @@ cc_library_with_stable_tflite_abi(
     name = "utils",
     srcs = ["utils.cc"],
     hdrs = ["utils.h"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ["-fexceptions"],
     non_stable_abi_deps = [
         "//tensorflow/lite/delegates/nnapi:nnapi_delegate",
     ] + select({
@@ -51,12 +51,12 @@ cc_library_with_stable_tflite_abi(
             "//tensorflow/lite/delegates/coreml:coreml_delegate",
         ],
         "//conditions:default": [],
-    }) + select({
-        "//tensorflow/lite/delegates/gpu:supports_gpu_delegate": [
-            "//tensorflow/lite/delegates/gpu:delegate",
-        ],
+     }) + select({
+             "//tensorflow/lite/delegates/gpu:supports_gpu_delegate": [
+	     "//tensorflow/lite/delegates/gpu:delegate",
+	     ],
         "//conditions:default": [],
-    }) + select({
+     }) + select({
         "//tensorflow:arm_any": [
             "//tensorflow/lite/delegates/hexagon:hexagon_delegate",
         ],
@@ -88,7 +88,7 @@ cc_library(
     name = "evaluation_delegate_provider",
     srcs = ["evaluation_delegate_provider.cc"],
     hdrs = ["evaluation_delegate_provider.h"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ["-fexceptions"],
     deps = [
         ":utils",
         "//tensorflow/lite/tools:command_line_flags",
diff --git a/tensorflow/lite/tools/evaluation/stages/BUILD b/tensorflow/lite/tools/evaluation/stages/BUILD
index 2ebe3a67bd72..da75a3e01c93 100644
--- a/tensorflow/lite/tools/evaluation/stages/BUILD
+++ b/tensorflow/lite/tools/evaluation/stages/BUILD
@@ -104,7 +104,7 @@ cc_library(
     name = "tflite_inference_stage",
     srcs = ["tflite_inference_stage.cc"],
     hdrs = ["tflite_inference_stage.h"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ['-fexceptions'],
     deps = [
         "//tensorflow/core:tflite_portable_logging",
         "//tensorflow/lite:framework",
@@ -163,7 +163,7 @@ cc_library(
     name = "inference_profiler_stage",
     srcs = ["inference_profiler_stage.cc"],
     hdrs = ["inference_profiler_stage.h"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ['-fexceptions'],
     deps = [
         ":tflite_inference_stage",
         "//tensorflow/core:tflite_portable_logging",
diff --git a/tensorflow/lite/tools/evaluation/tasks/BUILD b/tensorflow/lite/tools/evaluation/tasks/BUILD
index a1d0a37d8168..a387315e4e32 100644
--- a/tensorflow/lite/tools/evaluation/tasks/BUILD
+++ b/tensorflow/lite/tools/evaluation/tasks/BUILD
@@ -18,7 +18,7 @@ cc_library(
     name = "task_executor",
     srcs = ["task_executor.cc"],
     hdrs = ["task_executor.h"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ['-fexceptions'],
     linkopts = task_linkopts(),
     deps = [
         "//tensorflow/lite/tools:command_line_flags",
@@ -32,7 +32,7 @@ cc_library(
 cc_library(
     name = "task_executor_main",
     srcs = ["task_executor_main.cc"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ['-fexceptions'],
     linkopts = task_linkopts(),
     deps = [
         ":task_executor",
diff --git a/tensorflow/lite/tools/evaluation/tasks/inference_diff/BUILD b/tensorflow/lite/tools/evaluation/tasks/inference_diff/BUILD
index 0c6cf3e67f90..243c605bb526 100644
--- a/tensorflow/lite/tools/evaluation/tasks/inference_diff/BUILD
+++ b/tensorflow/lite/tools/evaluation/tasks/inference_diff/BUILD
@@ -12,7 +12,7 @@ package(
 cc_library(
     name = "run_eval_lib",
     srcs = ["run_eval.cc"],
-    copts = tflite_copts(),
+    copts = tflite_copts() + ['-fexceptions'],
     linkopts = task_linkopts(),
     deps = [
         "//tensorflow/lite/core/c:common",
@@ -30,7 +30,7 @@ cc_library(
 
 cc_binary(
     name = "run_eval",
-    copts = tflite_copts(),
+    copts = tflite_copts() + ['-fexceptions'],
     linkopts = task_linkopts(),
     deps = [
         ":run_eval_lib",
diff --git a/tensorflow/lite/tools/evaluation/utils.cc b/tensorflow/lite/tools/evaluation/utils.cc
index 28523a5034f8..11fc313fdd2b 100644
--- a/tensorflow/lite/tools/evaluation/utils.cc
+++ b/tensorflow/lite/tools/evaluation/utils.cc
@@ -261,6 +261,19 @@ TfLiteDelegatePtr CreateCoreMlDelegate() {
   return tools::CreateNullDelegate();
 #endif  // REAL_IPHONE_DEVICE
 }
+/*TfLiteDelegatePtr CreateOPENVINODelegate() {
+  TfLiteOpenVINODelegateOptions openvino_options =
+      TfLiteOpenVINODelegateOptionsDefault();
+  return CreateOPENVINODelegate(&openvino_options);
+}
+
+TfLiteDelegatePtr CreateOPENVINODelegate(
+    const TfLiteOpenVINODelegateOptions* openvino_options) {
+  auto openvino_delegate = TfLiteCreateOpenVINODelegate(openvino_options);
+  return TfLiteDelegatePtr(openvino_delegate, [](TfLiteDelegate* delegate) {
+    TfLiteDeleteOpenVINODelegate(delegate);
+  });
+}*/
 
 }  // namespace evaluation
 }  // namespace tflite
diff --git a/third_party/openvino/openvino.bzl b/third_party/openvino/openvino.bzl
new file mode 100644
index 000000000000..a5721b3082b8
--- /dev/null
+++ b/third_party/openvino/openvino.bzl
@@ -0,0 +1,20 @@
+def _openvino_native_impl(repository_ctx):
+    openvino_native_dir = "/build/rex/usr/local"
+    repository_ctx.symlink(openvino_native_dir, "openvino")
+    repository_ctx.file("BUILD", """
+cc_library(
+    name = "openvino",
+    hdrs = glob(["openvino/runtime/include", "openvino/runtime/include/ie/cpp", "openvino/runtime/include/ie"]),
+    srcs = ["openvino/lib64/libopenvino.so.2023.3.0"],
+    includes = ["openvino/runtime/include/ie/cpp",
+                "openvino/runtime/include/ie",
+                "openvino/runtime/include"],
+    visibility = ["//visibility:public"],
+)
+    """)
+
+openvino_configure = repository_rule(
+    implementation = _openvino_native_impl,
+    local = True,
+    environ = ["OPENVINO_NATIVE_DIR"],
+)
diff --git a/tools/build_tfmodel.py b/tools/build_tfmodel.py
new file mode 100644
index 000000000000..08022a2a52e8
--- /dev/null
+++ b/tools/build_tfmodel.py
@@ -0,0 +1,152 @@
+import tensorflow as tf
+from tensorflow import random
+import os
+import sys
+
+def build_model(op_type):
+    if (op_type == "conv2d"):
+            input_shape = (5, 5, 1)
+            x_train = tf.random.normal(input_shape, mean = 0.0, stddev = 1.0)
+
+            in_layer = tf.keras.layers.Input(shape=input_shape)
+            conv2d_layer = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3)) (in_layer)
+##            print (" Shape is " + str(conv2d_layer.output_shape))
+            model = tf.keras.Model(in_layer, conv2d_layer)
+            model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])
+            for layer in model.layers:
+                print(layer.output_shape)
+            model.summary()
+            #model.fit(x_train, y_train, epochs=5, batch_size=32)
+
+            export_dir = os.path.join(os.getcwd(), op_type)
+            os.makedirs(export_dir, exist_ok=True)
+            tf.saved_model.save(model, export_dir)
+            converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
+            tflite_model = converter.convert()
+            tflite_file = os.path.join(export_dir, 'conv2d_model.tflite')
+            with open(tflite_file, 'wb') as f:
+                f.write(tflite_model)
+
+            print(f"model saved at {export_dir}")
+
+    if (op_type == "relu6"):
+            fit_model = False
+
+            input_shape = (5, 5, 1)
+            x_train = tf.random.normal(input_shape, mean = 0.0, stddev = 1.0)
+
+            in_layer = tf.keras.layers.Input(shape=input_shape)
+            #conv2d_layer = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3)) (in_layer)
+            relu_layer = tf.keras.layers.ReLU(6.0) (in_layer)
+            model = tf.keras.Model(in_layer, relu_layer)
+
+            model.compile(optimizer='adam',  loss='categorical_crossentropy', metrics=['accuracy'])
+
+            x_shape = (128,1)
+            x_train  = tf.random.normal(x_shape, mean = 0.0, stddev = 1.0)
+
+            y_shape = (1,)
+            y_train  = tf.random.uniform(y_shape, minval=0, maxval=1,dtype=tf.int32)
+            model.build(x_shape)
+
+            model.summary()
+
+            if fit_model:
+                model.fit(x_train, y_train, epochs=2)
+
+            export_dir = os.path.join(os.getcwd(), op_type)
+            os.makedirs(export_dir, exist_ok=True)
+            tf.saved_model.save(model, export_dir)
+            converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
+            tflite_model = converter.convert()
+            tflite_file = os.path.join(export_dir, 'relu6_model.tflite')
+            with open(tflite_file, 'wb') as f:
+                f.write(tflite_model)
+
+            print(f"model saved at {export_dir}")
+    if (op_type == "relu"):
+            fit_model = False
+
+            input_shape = (5, 5, 1)
+            x_train = tf.random.normal(input_shape, mean = 0.0, stddev = 1.0)
+
+            in_layer = tf.keras.layers.Input(shape=input_shape)
+            #conv2d_layer = tf.keras.layers.Conv2D(filters=1, kernel_size=(3,3)) (in_layer)
+            relu_layer = tf.keras.layers.ReLU() (in_layer)
+            model = tf.keras.Model(in_layer, relu_layer)
+
+            model.compile(optimizer='adam',  loss='categorical_crossentropy', metrics=['accuracy'])
+
+            x_shape = (128,1)
+            x_train  = tf.random.normal(x_shape, mean = 0.0, stddev = 1.0)
+
+            y_shape = (1,)
+            y_train  = tf.random.uniform(y_shape, minval=0, maxval=1,dtype=tf.int32)
+            model.build(x_shape)
+
+            model.summary()
+
+            if fit_model:
+                model.fit(x_train, y_train, epochs=2)
+
+            export_dir = os.path.join(os.getcwd(), op_type)
+            os.makedirs(export_dir, exist_ok=True)
+            tf.saved_model.save(model, export_dir)
+            converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
+            tflite_model = converter.convert()
+            tflite_file = os.path.join(export_dir, 'relu_model.tflite')
+            with open(tflite_file, 'wb') as f:
+                f.write(tflite_model)
+
+            print(f"model saved at {export_dir}")
+
+    if (op_type == "logistic"):
+            input_shape = (5, 5, 1)
+            x_train = tf.random.normal(input_shape, mean = 0.0, stddev = 1.0)
+
+            in_layer = tf.keras.layers.Input(shape=input_shape)
+            logistic_layer = tf.keras.activations.sigmoid(in_layer)
+            model = tf.keras.Model(in_layer, logistic_layer)
+            model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])
+            for layer in model.layers:
+                print(layer.output_shape)
+            model.summary()
+
+            export_dir = os.path.join(os.getcwd(), op_type)
+            os.makedirs(export_dir, exist_ok=True)
+            tf.saved_model.save(model, export_dir)
+            converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
+            tflite_model = converter.convert()
+            tflite_file = os.path.join(export_dir, 'logistic_model.tflite')
+            with open(tflite_file, 'wb') as f:
+                f.write(tflite_model)
+
+            print(f"model saved at {export_dir}")
+
+    if (op_type == "mul"):
+            input1 = tf.keras.layers.Input(shape=(32,))
+            input2 = tf.keras.layers.Input(shape=(32,))
+            multiplied = tf.keras.layers.multiply([input1, input2])
+            model = tf.keras.models.Model(inputs=[input1, input2], outputs=multiplied)
+
+            model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])
+            for layer in model.layers:
+                print(layer.output_shape)
+            model.summary()
+
+            export_dir = os.path.join(os.getcwd(), op_type)
+            os.makedirs(export_dir, exist_ok=True)
+            tf.saved_model.save(model, export_dir)
+            converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
+            tflite_model = converter.convert()
+            tflite_file = os.path.join(export_dir, 'mul_model.tflite')
+            with open(tflite_file, 'wb') as f:
+                f.write(tflite_model)
+
+            print(f"model saved at {export_dir}")
+
+def main():
+    print(f"building {sys.argv[1]}")
+    build_model(sys.argv[1])
+
+main()
-- 
2.34.1

